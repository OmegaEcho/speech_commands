{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this is a notebook for speech siamese. \n",
    "the goal is to add siamese network after the speech command network to make a one-shot speech command model. with this model, take two piece of audio as input, the model will tell if it is the same speech command or not. \n",
    "if the accuracy is good enough, we make take it input product for voice trigger or voice command which are useful for all kind of product. \n",
    "\n",
    "the trick may be if siamese can make one shot accure enough. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import hashlib\n",
    "import math, time, datetime\n",
    "import os.path\n",
    "import random\n",
    "import re\n",
    "import sys\n",
    "import tarfile\n",
    "\n",
    "#print(sys.executable)\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import librosa as rosa\n",
    "import librosa.display\n",
    "from six.moves import urllib\n",
    "from six.moves import xrange  # pylint: disable=redefined-builtin\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Input, concatenate, Dense, Conv2D, MaxPooling2D, Dropout, Flatten, Lambda, BatchNormalization, Activation, LSTM, GRU\n",
    "#from tensorflow.contrib.framework.python.ops import audio_ops as contrib_audio\n",
    "#from tensorflow.python.ops import io_ops\n",
    "#from tensorflow.python.platform import gfile\n",
    "#from tensorflow.python.util import compat\n",
    "\n",
    "default_number_of_mfcc=128\n",
    "default_sample_rate=16000\n",
    "default_hop_length=512 \n",
    "default_wav_duration=1 # 1 second\n",
    "default_train_samples=10000\n",
    "default_test_samples=100\n",
    "default_epochs=10\n",
    "default_batch_size=256\n",
    "default_wanted_words=[\"one\", \"two\", \"bed\", \"backward\", \"bird\", \"cat\", \"dog\", \"eight\", \"five\", \"follow\", \"forward\", \"four\", \"go\", \"happy\", \"house\", \"learn\", \"left\", \"marvin\", \"nine\", \"no\", \"off\", \"right\", \"seven\", \"sheila\", \"stop\", \"three\", \"tree\", \"visual\", \"wow\", \"zero\",\"up\"]\n",
    "#for mac\n",
    "#speech_data_dir=\"/Users/hermitwang/Downloads/speech_dataset\"\n",
    "#default_model_path=\"/Users/hermitwang/Downloads/pretrained/speech_siamese\"\n",
    "#for ubuntu\n",
    "#speech_data_dir=\"/home/hermitwang/TrainingData/datasets/speech_dataset\"\n",
    "#default_model_path=\"/home/hermitwang/TrainingData/pretrained/speech_siamese\"\n",
    "#for windows of work\n",
    "#speech_data_dir=\"D:\\\\HermitWang\\\\DeepLearning\\\\dataset\\\\speech_dataset\"\n",
    "#default_model_path=\"D:\\\\HermitWang\\\\DeepLearning\\\\dataset\\\\trained\\\\siamese\"\n",
    "#for himl \n",
    "speech_data_dir=\"D:\\jun\\speech_commands-master\\dataset\"\n",
    "default_model_path=\"D:\\jun\\speech_commands-master\\\\trained\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_wav_mfcc(filename):\n",
    "    wav_loader, sample_rate = rosa.load(filename, sr=default_sample_rate)\n",
    "    #print(rosa.get_duration(wav_loader, sample_rate))\n",
    "    wav_mfcc = rosa.feature.mfcc(y=wav_loader, sr=default_sample_rate, n_mfcc=default_number_of_mfcc)\n",
    "    wav_mfcc = np.transpose(wav_mfcc)\n",
    "    return wav_mfcc\n",
    "\n",
    "def get_default_mfcc_length(default_wav_duration=1):\n",
    "    length = int(math.ceil(default_wav_duration * default_sample_rate / default_hop_length))\n",
    "    return length\n",
    "\n",
    "def mfcc_display(mfccs):\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    librosa.display.specshow(mfccs, x_axis='time')\n",
    "    plt.colorbar()\n",
    "    plt.title('MFCC')\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class WavMFCCLoader(object):\n",
    "    def __init__(self, data_dir, wanted, validation_percentage=0, testing_percentage=0):\n",
    "        self.data_dir = data_dir\n",
    "        self.wanted = wanted\n",
    "        self.default_mfcc_length=get_default_mfcc_length(default_wav_duration)\n",
    "        self.wav_files = dict()\n",
    "        self.wav_file_index()\n",
    "        \n",
    "    def wav_file_index(self):\n",
    "        for dirpath, dirnames, files in os.walk(self.data_dir):\n",
    "            for name in files:\n",
    "                if name.lower().endswith('.wav'):\n",
    "                    #for windows\n",
    "                    word_name = dirpath.rsplit('\\\\', 1)[1];\n",
    "                    #for others\n",
    "                    #word_name = dirpath.rsplit('/', 1)[1];\n",
    "                    if word_name in self.wanted:\n",
    "                        file_name = os.path.join(dirpath, name)\n",
    "                        #print(file_name, dirpath, word_name)\n",
    "    \n",
    "                        if word_name in self.wav_files.keys():\n",
    "                            self.wav_files[word_name].append(file_name)\n",
    "                        else:\n",
    "                            self.wav_files[word_name] = [file_name]\n",
    "                    \n",
    "        return self.wav_files\n",
    "\n",
    "\n",
    "    def wavs_to_mfcc_pair(self):\n",
    "        how_many_words = len(self.wanted)\n",
    "        a_index = random.randint(0, how_many_words - 1)\n",
    "        b_index = random.randint(0, how_many_words - 1)\n",
    "        a_wav_index = b_wav_index = -1\n",
    "        mfcc_pair = np.array([3, 1])\n",
    "        if (a_index > b_index):\n",
    "            a_wav_index = random.randint(0, len(self.wav_files[self.wanted[a_index]]) - 1)\n",
    "            b_wav_index = random.randint(0, len(self.wav_files[self.wanted[b_index]]) - 1)\n",
    "            mfcc_1 = load_wav_mfcc(self.wav_files[self.wanted[a_index]][a_wav_index])\n",
    "            mfcc_2 = load_wav_mfcc(self.wav_files[self.wanted[b_index]][b_wav_index])\n",
    "            mfcc_pair = 0            \n",
    "        else:\n",
    "            a_wav_index = random.randint(0, len(self.wav_files[self.wanted[a_index]]) - 1)\n",
    "            b_wav_index = random.randint(0, len(self.wav_files[self.wanted[a_index]]) - 1)\n",
    "            mfcc_1 = load_wav_mfcc(self.wav_files[self.wanted[a_index]][a_wav_index])\n",
    "            mfcc_2 = load_wav_mfcc(self.wav_files[self.wanted[a_index]][b_wav_index])\n",
    "            mfcc_pair = 1\n",
    "            \n",
    "        #print(\"aaa\", mfcc_1.shape, mfcc_2.shape)    \n",
    "        return mfcc_1, mfcc_2, mfcc_pair\n",
    "        \n",
    "    def get_mfcc_pairs(self, how_many):\n",
    "        mfcc1_data = np.zeros((how_many, self.default_mfcc_length, default_number_of_mfcc))\n",
    "        mfcc2_data = np.zeros((how_many, self.default_mfcc_length, default_number_of_mfcc))\n",
    "        same_data = np.zeros(how_many)\n",
    "        for i in range(0, how_many - 1):\n",
    "            \n",
    "            mfcc1_data_, mfcc2_data_, same_data[i] = self.wavs_to_mfcc_pair()\n",
    "            mfcc1_data[i, 0:mfcc1_data_.shape[0], : ] = mfcc1_data_\n",
    "            mfcc2_data[i, 0:mfcc2_data_.shape[0], : ] = mfcc2_data_\n",
    "            #np.append(mfcc1_data, mfcc1_)\n",
    "            #np.append(mfcc2_data, mfcc2_)\n",
    "            #np.append(same_data, same_)          \n",
    "        #print(mfcc_pairs)\n",
    "    \n",
    "        return mfcc1_data, mfcc2_data, same_data\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_cnn_model(fingerprint_shape, is_training=True):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(input_shape=fingerprint_shape, filters=64, kernel_size=3, use_bias=False))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(MaxPooling2D())\n",
    "    #if (is_training):\n",
    "    #    model.add(Dropout(0.5))\n",
    "    model.add(Conv2D(filters=64, kernel_size=3, use_bias=False)) \n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(\"relu\"))\n",
    "\n",
    "    model.add(MaxPooling2D())\n",
    "    #if (is_training):\n",
    "    #    model.add(Dropout(0.5))\n",
    "    model.add(Conv2D(filters=64, kernel_size=3, use_bias=False))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(\"relu\"))\n",
    "\n",
    "    model.add(MaxPooling2D())\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(256))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(\"sigmoid\"))\n",
    "    \n",
    "    return model\n",
    "\n",
    "def create_lstm_model(local_input_shape, is_training=True):\n",
    "    model = Sequential()\n",
    "    model.add(Reshape((local_input_shape[0], local_input_shape[1]), input_shape=local_input_shape))\n",
    "    model.add(Permute((2, 1)))\n",
    "    #model.add(BatchNormalization(input_shape=local_input_shape))\n",
    "    model.add(GRU(256, return_sequences=False, stateful=False))\n",
    "    #model.add(GRU(256, return_sequences=True, stateful=False))\n",
    "    #model.add(GRU(256, stateful=False))\n",
    "\n",
    "    model.add(Dense(256))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(\"sigmoid\")) \n",
    "    #if (is_training):\n",
    "    #    model.add(Dropout(0.5))\n",
    "    #model.add(Dense(labels_count, activation=\"softmax\"))\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def create_siamese_model(input_shape, siamese_mode = 'concat'):\n",
    "    right_cnn_input = Input(input_shape)\n",
    "    left_cnn_input = Input(input_shape)\n",
    "    \n",
    "    print(\"1:\", right_cnn_input.shape)\n",
    "    \n",
    "    cnn_model = create_cnn_model(input_shape)\n",
    "    lstm_model = create_lstm_model(input_shape)\n",
    "    \n",
    "    right_cnn_encoder = cnn_model(right_cnn_input)\n",
    "    right_lstm_encoder = lstm_model(right_cnn_input)\n",
    "    print(\"2:\", right_cnn_encoder.shape, right_lstm_encoder.shape)\n",
    "    \n",
    "    right_encoder = concatenate(inputs=[right_cnn_encoder, right_lstm_encoder])#, axis = 0)\n",
    "    print(\"3:\", right_encoder.shape)\n",
    "    \n",
    "    \n",
    "    left_cnn_encoder = cnn_model(left_cnn_input)\n",
    "    left_lstm_encoder = lstm_model(left_cnn_input)\n",
    "    left_encoder = concatenate(inputs=[left_cnn_encoder, left_lstm_encoder])#, axis = 0)\n",
    "    \n",
    "    if (siamese_mode == 'minus'):\n",
    "        concatenated_layer = Lambda(lambda x: x[0]-x[1], output_shape=lambda x: x[0])([right_encoder, left_encoder])\n",
    "    elif (siamese_mode == 'abs'):\n",
    "        concatenated_layer = Lambda(lambda x: tf.abs(x[0]-x[1]), output_shape=lambda x: x[0])([right_encoder, left_encoder])\n",
    "    elif (siamese_mode == 'innerP'):\n",
    "        concatenated_layer = Lambda(lambda x: np.dot(x[0],x[1]), output_shape=lambda x: x[0])([right_encoder, left_encoder])\n",
    "    #elif (siamese_mode == \"eu\"):\n",
    "         #concatenated_layer = Lambda(lambda x: tf.sqrt(tf.reduce_sum(tf.square(x[0]-x[1]), 2)), output_shape=lambda x: x[0])([right_encoder, left_encoder])\n",
    "    else:\n",
    "        raise ValueError(\"unknown siamese_mode\")\n",
    "        \n",
    "    output_layer = Dense(1, activation='sigmoid')(concatenated_layer)\n",
    "        \n",
    "    siamese_model = Model([right_cnn_input, left_cnn_input], output_layer)\n",
    "    return siamese_model\n",
    "    \n",
    "def siamese_train(local_siamese_mode='abs', train_samples=default_train_samples, wanted_words=default_wanted_words, local_batch_size=default_batch_size):\n",
    "    default_mfcc_length = get_default_mfcc_length(default_wav_duration)\n",
    "    siamese_model = create_siamese_model((default_number_of_mfcc, default_mfcc_length, 1), siamese_mode=local_siamese_mode)\n",
    "\n",
    "    siamese_model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "    loader = WavMFCCLoader(speech_data_dir, wanted=wanted_words)\n",
    "    mfcc1_data, mfcc2_data, pairs = loader.get_mfcc_pairs(train_samples)\n",
    "    \n",
    "    #x1_lstm_train = mfcc1_data\n",
    "    #x2_lstm_train = mfcc2_data\n",
    "    \n",
    "    mfcc1_data = np.transpose(mfcc1_data)\n",
    "    mfcc2_data = np.transpose(mfcc2_data)\n",
    "    x1_cnn_train = mfcc1_data.reshape((train_samples, default_number_of_mfcc, default_mfcc_length, 1)) #hop length is the time feature\n",
    "    x2_cnn_train = mfcc2_data.reshape((train_samples, default_number_of_mfcc, default_mfcc_length, 1)) #mfcc_number is the data feature\n",
    "    \n",
    "    y_train = pairs  #keras.utils.to_categorical(pairs, num_classes=1)\n",
    "    \n",
    "    \n",
    "    siamese_model.fit([x1_cnn_train, x2_cnn_train], y_train, epochs=3, batch_size=local_batch_size)\n",
    "    \n",
    "    \n",
    "    mfcc1_test, mfcc2_test, pairs_test = loader.get_mfcc_pairs(default_test_samples)\n",
    "    \n",
    "    #x1_lstm_test = mfcc1_test\n",
    "    #x2_lstm_test = mfcc2_test\n",
    "    \n",
    "    mfcc1_test = np.transpose(mfcc1_test)\n",
    "    mfcc2_test = np.transpose(mfcc2_test)\n",
    "    \n",
    "    x1_cnn_test = mfcc1_test.reshape((default_test_samples, default_number_of_mfcc, default_mfcc_length, 1))\n",
    "    x2_cnn_test = mfcc2_test.reshape((default_test_samples, default_number_of_mfcc, default_mfcc_length, 1))\n",
    "    y_test = pairs_test \n",
    "    \n",
    "    loss, accuracy = siamese_model.evaluate([x1_cnn_test, x2_cnn_test], y_test)    \n",
    "    \n",
    "    siamese_model.save(default_model_path+\"\\/speech_siamese.h5\")\n",
    "\n",
    "    print(loss)\n",
    "    return accuracy\n",
    "\n",
    "def siamese_test(test_samples=default_test_samples, wanted_words=default_wanted_words):\n",
    "    default_mfcc_length = get_default_mfcc_length(default_wav_duration)\n",
    "    loader = WavMFCCLoader(speech_data_dir, wanted=wanted_words)\n",
    "    siamese_model = keras.models.load_model(default_model_path+\"\\/speech_siamese.h5\")    \n",
    "    mfcc1_test, mfcc2_test, pairs_test = loader.get_mfcc_pairs(test_samples)\n",
    "    \n",
    "    #x1_lstm = mfcc1_test\n",
    "    #x2_lstm = mfcc2_test\n",
    "    \n",
    "    mfcc1_test = np.transpose(mfcc1_test)\n",
    "    mfcc2_test = np.transpose(mfcc2_test)\n",
    "    x1_cnn = mfcc1_test.reshape((test_samples, default_number_of_mfcc, default_mfcc_length, 1))\n",
    "    x2_cnn = mfcc2_test.reshape((test_samples, default_number_of_mfcc, default_mfcc_length, 1))\n",
    "    y_test = pairs_test \n",
    "    \n",
    "    loss, accuracy = siamese_model.test_on_batch(x=[x1_cnn, x2_cnn], y=y_test)\n",
    "    print(loss)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## main "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: (?, 128, 32, 1) (?, 32, 128)\n",
      "2: (?, 256) (?, 256)\n",
      "3: (?, 512)\n",
      "Epoch 1/3\n",
      "50/50 [==============================] - 7s 131ms/step - loss: 0.7489 - acc: 0.5400\n",
      "Epoch 2/3\n",
      "50/50 [==============================] - 3s 59ms/step - loss: 0.4140 - acc: 0.9000\n",
      "Epoch 3/3\n",
      "50/50 [==============================] - 3s 58ms/step - loss: 0.2320 - acc: 0.9800\n",
      "100/100 [==============================] - 2s 15ms/step\n",
      "0.702143840789795\n",
      "0.55\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "as_list() is not defined on an unknown TensorShape.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-da7fdf6f0174>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mscore\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msiamese_train\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlocal_siamese_mode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'minus'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlocal_batch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_samples\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwanted_words\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"one\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"two\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"cat\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"dog\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"bed\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"backward\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"eight\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"forward\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"four\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"go\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"happy\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"house\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"learn\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"left\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"marvin\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"nine\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"no\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"off\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"right\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"seven\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"sheila\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"stop\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"three\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"tree\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"visual\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"wow\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"zero\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"up\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mscore\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msiamese_test\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwanted_words\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"five\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"follow\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"bird\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-22-037532a19d55>\u001b[0m in \u001b[0;36msiamese_test\u001b[1;34m(test_samples, wanted_words)\u001b[0m\n\u001b[0;32m     84\u001b[0m     \u001b[0mdefault_mfcc_length\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_default_mfcc_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdefault_wav_duration\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m     \u001b[0mloader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mWavMFCCLoader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mspeech_data_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwanted\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mwanted_words\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 86\u001b[1;33m     \u001b[0msiamese_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdefault_model_path\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m\"\\/speech_siamese.h5\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     87\u001b[0m     \u001b[0mmfcc1_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmfcc2_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpairs_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_mfcc_pairs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_samples\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\jun\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\saving.py\u001b[0m in \u001b[0;36mload_model\u001b[1;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[0;32m    228\u001b[0m       \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'No model found in config file.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    229\u001b[0m     \u001b[0mmodel_config\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_config\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'utf-8'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 230\u001b[1;33m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_from_config\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_config\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    231\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    232\u001b[0m     \u001b[1;31m# set weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\jun\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\saving.py\u001b[0m in \u001b[0;36mmodel_from_config\u001b[1;34m(config, custom_objects)\u001b[0m\n\u001b[0;32m    308\u001b[0m                     '`Sequential.from_config(config)`?')\n\u001b[0;32m    309\u001b[0m   \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdeserialize\u001b[0m  \u001b[1;31m# pylint: disable=g-import-not-at-top\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 310\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mdeserialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    311\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\jun\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\serialization.py\u001b[0m in \u001b[0;36mdeserialize\u001b[1;34m(config, custom_objects)\u001b[0m\n\u001b[0;32m     62\u001b[0m       \u001b[0mmodule_objects\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mglobs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m       \u001b[0mcustom_objects\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m       printable_module_name='layer')\n\u001b[0m",
      "\u001b[1;32mD:\\jun\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\generic_utils.py\u001b[0m in \u001b[0;36mdeserialize_keras_object\u001b[1;34m(identifier, module_objects, custom_objects, printable_module_name)\u001b[0m\n\u001b[0;32m    171\u001b[0m             custom_objects=dict(\n\u001b[0;32m    172\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_GLOBAL_CUSTOM_OBJECTS\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 173\u001b[1;33m                 list(custom_objects.items())))\n\u001b[0m\u001b[0;32m    174\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mCustomObjectScope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    175\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_config\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'config'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\jun\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\network.py\u001b[0m in \u001b[0;36mfrom_config\u001b[1;34m(cls, config, custom_objects)\u001b[0m\n\u001b[0;32m   1290\u001b[0m     \u001b[1;31m# First, we create all layers and enqueue nodes to be processed\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1291\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mlayer_data\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'layers'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1292\u001b[1;33m       \u001b[0mprocess_layer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayer_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1293\u001b[0m     \u001b[1;31m# Then we process nodes in order of layer depth.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1294\u001b[0m     \u001b[1;31m# Nodes that cannot yet be processed (if the inbound node\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\jun\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\network.py\u001b[0m in \u001b[0;36mprocess_layer\u001b[1;34m(layer_data)\u001b[0m\n\u001b[0;32m   1276\u001b[0m       \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdeserialize\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mdeserialize_layer\u001b[0m  \u001b[1;31m# pylint: disable=g-import-not-at-top\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1277\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1278\u001b[1;33m       \u001b[0mlayer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdeserialize_layer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayer_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1279\u001b[0m       \u001b[0mcreated_layers\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlayer_name\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1280\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\jun\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\serialization.py\u001b[0m in \u001b[0;36mdeserialize\u001b[1;34m(config, custom_objects)\u001b[0m\n\u001b[0;32m     62\u001b[0m       \u001b[0mmodule_objects\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mglobs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m       \u001b[0mcustom_objects\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m       printable_module_name='layer')\n\u001b[0m",
      "\u001b[1;32mD:\\jun\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\generic_utils.py\u001b[0m in \u001b[0;36mdeserialize_keras_object\u001b[1;34m(identifier, module_objects, custom_objects, printable_module_name)\u001b[0m\n\u001b[0;32m    171\u001b[0m             custom_objects=dict(\n\u001b[0;32m    172\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_GLOBAL_CUSTOM_OBJECTS\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 173\u001b[1;33m                 list(custom_objects.items())))\n\u001b[0m\u001b[0;32m    174\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mCustomObjectScope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    175\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_config\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'config'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\jun\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py\u001b[0m in \u001b[0;36mfrom_config\u001b[1;34m(cls, config, custom_objects)\u001b[0m\n\u001b[0;32m    340\u001b[0m       \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    341\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mbuild_input_shape\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 342\u001b[1;33m       \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbuild_input_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    343\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\jun\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py\u001b[0m in \u001b[0;36mbuild\u001b[1;34m(self, input_shape)\u001b[0m\n\u001b[0;32m    220\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    221\u001b[0m           \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 222\u001b[1;33m             \u001b[0mlayer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    223\u001b[0m           \u001b[0mlayer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuilt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m         \u001b[0mshape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompute_output_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\jun\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\tf_utils.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(instance, input_shape)\u001b[0m\n\u001b[0;32m    144\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    145\u001b[0m         input_shape = [\n\u001b[1;32m--> 146\u001b[1;33m             tuple(tensor_shape.TensorShape(x).as_list()) for x in input_shape]\n\u001b[0m\u001b[0;32m    147\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    148\u001b[0m         \u001b[0minput_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor_shape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensorShape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\jun\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\tf_utils.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    144\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    145\u001b[0m         input_shape = [\n\u001b[1;32m--> 146\u001b[1;33m             tuple(tensor_shape.TensorShape(x).as_list()) for x in input_shape]\n\u001b[0m\u001b[0;32m    147\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    148\u001b[0m         \u001b[0minput_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor_shape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensorShape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\jun\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_shape.py\u001b[0m in \u001b[0;36mas_list\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    902\u001b[0m     \"\"\"\n\u001b[0;32m    903\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dims\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 904\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"as_list() is not defined on an unknown TensorShape.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    905\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mdim\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dims\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    906\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: as_list() is not defined on an unknown TensorShape."
     ]
    }
   ],
   "source": [
    "score=siamese_train(local_siamese_mode='minus', local_batch_size=32, train_samples=50, wanted_words=[\"one\", \"two\", \"cat\", \"dog\", \"bed\", \"backward\", \"eight\",\"forward\", \"four\", \"go\", \"happy\", \"house\", \"learn\", \"left\", \"marvin\", \"nine\", \"no\", \"off\", \"right\", \"seven\", \"sheila\", \"stop\", \"three\", \"tree\", \"visual\", \"wow\", \"zero\",\"up\"])\n",
    "print(score)\n",
    "score=siamese_test(wanted_words=[\"five\", \"follow\", \"bird\"])\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# history\n",
    "Train batch size32 of 10000 run:\n",
    "Epoch 1/10\n",
    "10000/10000 [==============================] - 51s 5ms/step - loss: 0.6747 - acc: 0.5909\n",
    "Epoch 2/10\n",
    "10000/10000 [==============================] - 39s 4ms/step - loss: 0.6077 - acc: 0.6699\n",
    "Epoch 3/10\n",
    "10000/10000 [==============================] - 39s 4ms/step - loss: 0.5475 - acc: 0.7214\n",
    "Epoch 4/10\n",
    "10000/10000 [==============================] - 39s 4ms/step - loss: 0.5103 - acc: 0.7490\n",
    "Epoch 5/10\n",
    "10000/10000 [==============================] - 39s 4ms/step - loss: 0.4746 - acc: 0.7739\n",
    "Epoch 6/10\n",
    "10000/10000 [==============================] - 39s 4ms/step - loss: 0.4526 - acc: 0.7864\n",
    "Epoch 7/10\n",
    "10000/10000 [==============================] - 39s 4ms/step - loss: 0.4179 - acc: 0.8058\n",
    "Epoch 8/10\n",
    "10000/10000 [==============================] - 39s 4ms/step - loss: 0.3952 - acc: 0.8212\n",
    "Epoch 9/10\n",
    "10000/10000 [==============================] - 39s 4ms/step - loss: 0.3543 - acc: 0.8431\n",
    "Epoch 10/10\n",
    "10000/10000 [==============================] - 39s 4ms/step - loss: 0.3331 - acc: 0.8556\n",
    "100/100 [==============================] - 5s 49ms/step\n",
    "0.6359951663017273\n",
    "0.66\n",
    "0.789345\n",
    "0.64\n",
    "Train batch size64 of 10000 run:\n",
    "Epoch 1/10\n",
    "10000/10000 [==============================] - 33s 3ms/step - loss: 0.6584 - acc: 0.6088\n",
    "Epoch 2/10\n",
    "10000/10000 [==============================] - 20s 2ms/step - loss: 0.5588 - acc: 0.7170\n",
    "Epoch 3/10\n",
    "10000/10000 [==============================] - 20s 2ms/step - loss: 0.4976 - acc: 0.7541\n",
    "Epoch 4/10\n",
    "10000/10000 [==============================] - 20s 2ms/step - loss: 0.4363 - acc: 0.7985\n",
    "Epoch 5/10\n",
    "10000/10000 [==============================] - 20s 2ms/step - loss: 0.3869 - acc: 0.8310\n",
    "Epoch 6/10\n",
    "10000/10000 [==============================] - 20s 2ms/step - loss: 0.3472 - acc: 0.8534\n",
    "Epoch 7/10\n",
    "10000/10000 [==============================] - 20s 2ms/step - loss: 0.2894 - acc: 0.8783\n",
    "Epoch 8/10\n",
    "10000/10000 [==============================] - 20s 2ms/step - loss: 0.2503 - acc: 0.9012\n",
    "Epoch 9/10\n",
    "10000/10000 [==============================] - 20s 2ms/step - loss: 0.2021 - acc: 0.9201\n",
    "Epoch 10/10\n",
    "10000/10000 [==============================] - 20s 2ms/step - loss: 0.1790 - acc: 0.9310\n",
    "100/100 [==============================] - 5s 51ms/step\n",
    "0.6375499749183655\n",
    "0.74\n",
    "0.75775427\n",
    "0.64\n",
    "Train batch size128 of 10000 run:\n",
    "Epoch 1/10\n",
    "10000/10000 [==============================] - 24s 2ms/step - loss: 0.6545 - acc: 0.6106\n",
    "Epoch 2/10\n",
    "10000/10000 [==============================] - 11s 1ms/step - loss: 0.5306 - acc: 0.7404\n",
    "Epoch 3/10\n",
    "10000/10000 [==============================] - 11s 1ms/step - loss: 0.4484 - acc: 0.7980\n",
    "Epoch 4/10\n",
    "10000/10000 [==============================] - 11s 1ms/step - loss: 0.3578 - acc: 0.8505\n",
    "Epoch 5/10\n",
    "10000/10000 [==============================] - 11s 1ms/step - loss: 0.2842 - acc: 0.8883\n",
    "Epoch 6/10\n",
    "10000/10000 [==============================] - 11s 1ms/step - loss: 0.2226 - acc: 0.9181\n",
    "Epoch 7/10\n",
    "10000/10000 [==============================] - 11s 1ms/step - loss: 0.1554 - acc: 0.9488\n",
    "Epoch 8/10\n",
    "10000/10000 [==============================] - 11s 1ms/step - loss: 0.1174 - acc: 0.9622\n",
    "Epoch 9/10\n",
    "10000/10000 [==============================] - 11s 1ms/step - loss: 0.0915 - acc: 0.9719\n",
    "Epoch 10/10\n",
    "10000/10000 [==============================] - 11s 1ms/step - loss: 0.0768 - acc: 0.9773\n",
    "100/100 [==============================] - 5s 52ms/step\n",
    "0.8552563941478729\n",
    "0.66\n",
    "0.84699136\n",
    "0.63\n",
    "Train batch size256 of 10000 run:\n",
    "Epoch 1/10\n",
    "10000/10000 [==============================] - 23s 2ms/step - loss: 0.6719 - acc: 0.6132\n",
    "Epoch 2/10\n",
    "10000/10000 [==============================] - 9s 928us/step - loss: 0.5364 - acc: 0.7326\n",
    "Epoch 3/10\n",
    "10000/10000 [==============================] - 9s 921us/step - loss: 0.4372 - acc: 0.8051\n",
    "Epoch 4/10\n",
    "10000/10000 [==============================] - 9s 922us/step - loss: 0.3432 - acc: 0.8641\n",
    "Epoch 5/10\n",
    "10000/10000 [==============================] - 9s 921us/step - loss: 0.2468 - acc: 0.9153\n",
    "Epoch 6/10\n",
    "10000/10000 [==============================] - 9s 925us/step - loss: 0.1678 - acc: 0.9525\n",
    "Epoch 7/10\n",
    "10000/10000 [==============================] - 9s 924us/step - loss: 0.1088 - acc: 0.9741\n",
    "Epoch 8/10\n",
    "10000/10000 [==============================] - 9s 925us/step - loss: 0.0757 - acc: 0.9844\n",
    "Epoch 9/10\n",
    "10000/10000 [==============================] - 9s 927us/step - loss: 0.0545 - acc: 0.9895\n",
    "Epoch 10/10\n",
    "10000/10000 [==============================] - 9s 928us/step - loss: 0.0402 - acc: 0.9930\n",
    "100/100 [==============================] - 5s 54ms/step\n",
    "1.0554559028148651\n",
    "0.64\n",
    "1.004274\n",
    "0.61\n",
    "Train batch size512 of 10000 run:\n",
    "Epoch 1/10\n",
    "10000/10000 [==============================] - 25s 3ms/step - loss: 0.6903 - acc: 0.5837\n",
    "Epoch 2/10\n",
    "10000/10000 [==============================] - 11s 1ms/step - loss: 0.5722 - acc: 0.7042\n",
    "Epoch 3/10\n",
    "10000/10000 [==============================] - 11s 1ms/step - loss: 0.4611 - acc: 0.7951\n",
    "Epoch 4/10\n",
    "10000/10000 [==============================] - 11s 1ms/step - loss: 0.3503 - acc: 0.8692\n",
    "Epoch 5/10\n",
    "10000/10000 [==============================] - 11s 1ms/step - loss: 0.2526 - acc: 0.9187\n",
    "Epoch 6/10\n",
    "10000/10000 [==============================] - 11s 1ms/step - loss: 0.1539 - acc: 0.9640\n",
    "Epoch 7/10\n",
    "10000/10000 [==============================] - 11s 1ms/step - loss: 0.0836 - acc: 0.9876\n",
    "Epoch 8/10\n",
    "10000/10000 [==============================] - 11s 1ms/step - loss: 0.0479 - acc: 0.9944\n",
    "Epoch 9/10\n",
    "10000/10000 [==============================] - 11s 1ms/step - loss: 0.0392 - acc: 0.9933\n",
    "Epoch 10/10\n",
    "10000/10000 [==============================] - 11s 1ms/step - loss: 0.0074 - acc: 0.9997\n",
    "100/100 [==============================] - 6s 57ms/step\n",
    "0.8289524644613266\n",
    "0.71\n",
    "1.1377285\n",
    "0.59\n",
    "Train batch size32 of 20000 run:\n",
    "Epoch 1/10\n",
    "20000/20000 [==============================] - 92s 5ms/step - loss: 0.6445 - acc: 0.6255\n",
    "Epoch 2/10\n",
    "20000/20000 [==============================] - 77s 4ms/step - loss: 0.5653 - acc: 0.7045\n",
    "Epoch 3/10\n",
    "20000/20000 [==============================] - 77s 4ms/step - loss: 0.5279 - acc: 0.7379\n",
    "Epoch 4/10\n",
    "20000/20000 [==============================] - 76s 4ms/step - loss: 0.5014 - acc: 0.7542\n",
    "Epoch 5/10\n",
    "20000/20000 [==============================] - 77s 4ms/step - loss: 0.4761 - acc: 0.7742\n",
    "Epoch 6/10\n",
    "20000/20000 [==============================] - 76s 4ms/step - loss: 0.4572 - acc: 0.7862\n",
    "Epoch 7/10\n",
    "20000/20000 [==============================] - 77s 4ms/step - loss: 0.4353 - acc: 0.7998\n",
    "Epoch 8/10\n",
    "20000/20000 [==============================] - 77s 4ms/step - loss: 0.4154 - acc: 0.8090\n",
    "Epoch 9/10\n",
    "20000/20000 [==============================] - 77s 4ms/step - loss: 0.3938 - acc: 0.8201\n",
    "Epoch 10/10\n",
    "20000/20000 [==============================] - 76s 4ms/step - loss: 0.3733 - acc: 0.8327\n",
    "100/100 [==============================] - 6s 59ms/step\n",
    "0.48755233764648437\n",
    "0.74\n",
    "0.66804606\n",
    "0.67\n",
    "Train batch size64 of 20000 run:\n",
    "Epoch 1/10\n",
    "20000/20000 [==============================] - 55s 3ms/step - loss: 0.6281 - acc: 0.6425\n",
    "Epoch 2/10\n",
    "20000/20000 [==============================] - 40s 2ms/step - loss: 0.5251 - acc: 0.7407\n",
    "Epoch 3/10\n",
    "20000/20000 [==============================] - 40s 2ms/step - loss: 0.4769 - acc: 0.7744\n",
    "Epoch 4/10\n",
    "20000/20000 [==============================] - 40s 2ms/step - loss: 0.4345 - acc: 0.8016\n",
    "Epoch 5/10\n",
    "20000/20000 [==============================] - 40s 2ms/step - loss: 0.3903 - acc: 0.8294\n",
    "Epoch 6/10\n",
    "20000/20000 [==============================] - 40s 2ms/step - loss: 0.3579 - acc: 0.8422\n",
    "Epoch 7/10\n",
    "20000/20000 [==============================] - 40s 2ms/step - loss: 0.3295 - acc: 0.8570\n",
    "Epoch 8/10\n",
    "20000/20000 [==============================] - 40s 2ms/step - loss: 0.2930 - acc: 0.8771\n",
    "Epoch 9/10\n",
    "20000/20000 [==============================] - 40s 2ms/step - loss: 0.2680 - acc: 0.8887\n",
    "Epoch 10/10\n",
    "20000/20000 [==============================] - 40s 2ms/step - loss: 0.2400 - acc: 0.8990\n",
    "100/100 [==============================] - 6s 61ms/step\n",
    "0.47803831458091733\n",
    "0.8\n",
    "0.76065034\n",
    "0.63\n",
    "Train batch size128 of 20000 run:\n",
    "Epoch 1/10\n",
    "20000/20000 [==============================] - 47s 2ms/step - loss: 0.6311 - acc: 0.6420\n",
    "Epoch 2/10\n",
    "20000/20000 [==============================] - 31s 2ms/step - loss: 0.5158 - acc: 0.7477\n",
    "Epoch 3/10\n",
    "20000/20000 [==============================] - 31s 2ms/step - loss: 0.4547 - acc: 0.7903\n",
    "Epoch 4/10\n",
    "20000/20000 [==============================] - 31s 2ms/step - loss: 0.4002 - acc: 0.8207\n",
    "Epoch 5/10\n",
    "20000/20000 [==============================] - 31s 2ms/step - loss: 0.3480 - acc: 0.8497\n",
    "Epoch 6/10\n",
    "20000/20000 [==============================] - 30s 2ms/step - loss: 0.2973 - acc: 0.8759\n",
    "Epoch 7/10\n",
    "20000/20000 [==============================] - 30s 2ms/step - loss: 0.2593 - acc: 0.8960\n",
    "Epoch 8/10\n",
    "20000/20000 [==============================] - 31s 2ms/step - loss: 0.2154 - acc: 0.9134\n",
    "Epoch 9/10\n",
    "20000/20000 [==============================] - 31s 2ms/step - loss: 0.1815 - acc: 0.9302\n",
    "Epoch 10/10\n",
    "20000/20000 [==============================] - 31s 2ms/step - loss: 0.1595 - acc: 0.9388\n",
    "100/100 [==============================] - 6s 64ms/step\n",
    "0.6838260662555694\n",
    "0.73\n",
    "1.1187925\n",
    "0.63\n",
    "Train batch size256 of 20000 run:\n",
    "Epoch 1/10\n",
    "20000/20000 [==============================] - 46s 2ms/step - loss: 0.6307 - acc: 0.6445\n",
    "Epoch 2/10\n",
    "20000/20000 [==============================] - 30s 1ms/step - loss: 0.5043 - acc: 0.7593\n",
    "Epoch 3/10\n",
    "20000/20000 [==============================] - 30s 1ms/step - loss: 0.4274 - acc: 0.8037\n",
    "Epoch 4/10\n",
    "20000/20000 [==============================] - 30s 1ms/step - loss: 0.3544 - acc: 0.8490\n",
    "Epoch 5/10\n",
    "20000/20000 [==============================] - 30s 1ms/step - loss: 0.2828 - acc: 0.8854\n",
    "Epoch 6/10\n",
    "20000/20000 [==============================] - 30s 1ms/step - loss: 0.2224 - acc: 0.9136\n",
    "Epoch 7/10\n",
    "20000/20000 [==============================] - 30s 1ms/step - loss: 0.1604 - acc: 0.9428\n",
    "Epoch 8/10\n",
    "20000/20000 [==============================] - 30s 1ms/step - loss: 0.1223 - acc: 0.9594\n",
    "Epoch 9/10\n",
    "20000/20000 [==============================] - 30s 2ms/step - loss: 0.0950 - acc: 0.9707\n",
    "Epoch 10/10\n",
    "20000/20000 [==============================] - 30s 1ms/step - loss: 0.0813 - acc: 0.9725\n",
    "100/100 [==============================] - 7s 66ms/step\n",
    "0.5451388466358185\n",
    "0.8\n",
    "1.336913\n",
    "0.52\n",
    "Train batch size512 of 20000 run:\n",
    "Epoch 1/10\n",
    "20000/20000 [==============================] - 44s 2ms/step - loss: 0.6569 - acc: 0.6202\n",
    "Epoch 2/10\n",
    "20000/20000 [==============================] - 28s 1ms/step - loss: 0.5155 - acc: 0.7490\n",
    "Epoch 3/10\n",
    "20000/20000 [==============================] - 28s 1ms/step - loss: 0.4283 - acc: 0.8087\n",
    "Epoch 4/10\n",
    "20000/20000 [==============================] - 28s 1ms/step - loss: 0.3430 - acc: 0.8566\n",
    "Epoch 5/10\n",
    "20000/20000 [==============================] - 28s 1ms/step - loss: 0.2625 - acc: 0.9007\n",
    "Epoch 6/10\n",
    "20000/20000 [==============================] - 28s 1ms/step - loss: 0.1880 - acc: 0.9385\n",
    "Epoch 7/10\n",
    "20000/20000 [==============================] - 28s 1ms/step - loss: 0.1275 - acc: 0.9619\n",
    "Epoch 8/10\n",
    "20000/20000 [==============================] - 28s 1ms/step - loss: 0.0864 - acc: 0.9788\n",
    "Epoch 9/10\n",
    "20000/20000 [==============================] - 28s 1ms/step - loss: 0.0628 - acc: 0.9856\n",
    "Epoch 10/10\n",
    "20000/20000 [==============================] - 28s 1ms/step - loss: 0.0454 - acc: 0.9906\n",
    "100/100 [==============================] - 7s 70ms/step\n",
    "0.6471694469451904\n",
    "0.73\n",
    "0.85942185\n",
    "0.6\n",
    "Train batch size32 of 30000 run:\n",
    "Epoch 1/10\n",
    "30000/30000 [==============================] - 233s 8ms/step - loss: 0.6237 - acc: 0.6469\n",
    "Epoch 2/10\n",
    "30000/30000 [==============================] - 216s 7ms/step - loss: 0.5391 - acc: 0.7250\n",
    "Epoch 3/10\n",
    "30000/30000 [==============================] - 216s 7ms/step - loss: 0.5005 - acc: 0.7527\n",
    "Epoch 4/10\n",
    "30000/30000 [==============================] - 216s 7ms/step - loss: 0.4730 - acc: 0.7734\n",
    "Epoch 5/10\n",
    "30000/30000 [==============================] - 217s 7ms/step - loss: 0.4498 - acc: 0.7906\n",
    "Epoch 6/10\n",
    "30000/30000 [==============================] - 216s 7ms/step - loss: 0.4295 - acc: 0.8007\n",
    "Epoch 7/10\n",
    "30000/30000 [==============================] - 216s 7ms/step - loss: 0.4101 - acc: 0.8128\n",
    "Epoch 8/10\n",
    "30000/30000 [==============================] - 216s 7ms/step - loss: 0.3896 - acc: 0.8248\n",
    "Epoch 9/10\n",
    "30000/30000 [==============================] - 216s 7ms/step - loss: 0.3761 - acc: 0.8311\n",
    "Epoch 10/10\n",
    "30000/30000 [==============================] - 216s 7ms/step - loss: 0.3549 - acc: 0.8445\n",
    "100/100 [==============================] - 7s 71ms/step\n",
    "0.37773097038269043\n",
    "0.83\n",
    "0.79266816\n",
    "0.59\n",
    "Train batch size64 of 30000 run:\n",
    "Epoch 1/10\n",
    "30000/30000 [==============================] - 157s 5ms/step - loss: 0.6030 - acc: 0.6722\n",
    "Epoch 2/10\n",
    "30000/30000 [==============================] - 140s 5ms/step - loss: 0.5096 - acc: 0.7482\n",
    "Epoch 3/10\n",
    "30000/30000 [==============================] - 140s 5ms/step - loss: 0.4643 - acc: 0.7805\n",
    "Epoch 4/10\n",
    "30000/30000 [==============================] - 140s 5ms/step - loss: 0.4244 - acc: 0.8053\n",
    "Epoch 5/10\n",
    "30000/30000 [==============================] - 140s 5ms/step - loss: 0.3912 - acc: 0.8236\n",
    "Epoch 6/10\n",
    "30000/30000 [==============================] - 140s 5ms/step - loss: 0.3642 - acc: 0.8402\n",
    "Epoch 7/10\n",
    "30000/30000 [==============================] - 140s 5ms/step - loss: 0.3354 - acc: 0.8544\n",
    "Epoch 8/10\n",
    "30000/30000 [==============================] - 140s 5ms/step - loss: 0.3108 - acc: 0.8666\n",
    "Epoch 9/10\n",
    "30000/30000 [==============================] - 140s 5ms/step - loss: 0.2866 - acc: 0.8778\n",
    "Epoch 10/10\n",
    "30000/30000 [==============================] - 140s 5ms/step - loss: 0.2729 - acc: 0.8849\n",
    "100/100 [==============================] - 7s 73ms/step\n",
    "0.3286512565612793\n",
    "0.86\n",
    "0.8987813\n",
    "0.63\n",
    "Train batch size128 of 30000 run:\n",
    "Epoch 1/10\n",
    "30000/30000 [==============================] - 114s 4ms/step - loss: 0.5948 - acc: 0.6756\n",
    "Epoch 2/10\n",
    "30000/30000 [==============================] - 95s 3ms/step - loss: 0.4871 - acc: 0.7652\n",
    "Epoch 3/10\n",
    "30000/30000 [==============================] - 95s 3ms/step - loss: 0.4292 - acc: 0.8018\n",
    "Epoch 4/10\n",
    "30000/30000 [==============================] - 95s 3ms/step - loss: 0.3804 - acc: 0.8295\n",
    "Epoch 5/10\n",
    "30000/30000 [==============================] - 95s 3ms/step - loss: 0.3406 - acc: 0.8522\n",
    "Epoch 6/10\n",
    "30000/30000 [==============================] - 95s 3ms/step - loss: 0.3064 - acc: 0.8692\n",
    "Epoch 7/10\n",
    "30000/30000 [==============================] - 95s 3ms/step - loss: 0.2679 - acc: 0.8890\n",
    "Epoch 8/10\n",
    "30000/30000 [==============================] - 95s 3ms/step - loss: 0.2408 - acc: 0.9024\n",
    "Epoch 9/10\n",
    "30000/30000 [==============================] - 95s 3ms/step - loss: 0.2129 - acc: 0.9118\n",
    "Epoch 10/10\n",
    "30000/30000 [==============================] - 95s 3ms/step - loss: 0.1873 - acc: 0.9253\n",
    "100/100 [==============================] - 8s 75ms/step\n",
    "0.5483711445331574\n",
    "0.8\n",
    "0.9686124\n",
    "0.6\n",
    "Train batch size256 of 30000 run:\n",
    "Epoch 1/10\n",
    "30000/30000 [==============================] - 88s 3ms/step - loss: 0.6031 - acc: 0.6652\n",
    "Epoch 2/10\n",
    "30000/30000 [==============================] - 69s 2ms/step - loss: 0.4728 - acc: 0.7756\n",
    "Epoch 3/10\n",
    "30000/30000 [==============================] - 69s 2ms/step - loss: 0.3940 - acc: 0.8249\n",
    "Epoch 4/10\n",
    "30000/30000 [==============================] - 69s 2ms/step - loss: 0.3261 - acc: 0.8624\n",
    "Epoch 5/10\n",
    "30000/30000 [==============================] - 69s 2ms/step - loss: 0.2679 - acc: 0.8912\n",
    "Epoch 6/10\n",
    "30000/30000 [==============================] - 69s 2ms/step - loss: 0.2129 - acc: 0.9169\n",
    "Epoch 7/10\n",
    "30000/30000 [==============================] - 69s 2ms/step - loss: 0.1675 - acc: 0.9361\n",
    "Epoch 8/10\n",
    "30000/30000 [==============================] - 69s 2ms/step - loss: 0.1345 - acc: 0.9515\n",
    "Epoch 9/10\n",
    "30000/30000 [==============================] - 69s 2ms/step - loss: 0.1100 - acc: 0.9607\n",
    "Epoch 10/10\n",
    "30000/30000 [==============================] - 69s 2ms/step - loss: 0.0952 - acc: 0.9661\n",
    "100/100 [==============================] - 8s 77ms/step\n",
    "0.4120274531841278\n",
    "0.84\n",
    "0.92830443\n",
    "0.68\n",
    "Train batch size512 of 30000 run:\n",
    "Epoch 1/10\n",
    "30000/30000 [==============================] - 69s 2ms/step - loss: 0.6204 - acc: 0.6538\n",
    "Epoch 2/10\n",
    "30000/30000 [==============================] - 49s 2ms/step - loss: 0.4703 - acc: 0.7814\n",
    "Epoch 3/10\n",
    "30000/30000 [==============================] - 49s 2ms/step - loss: 0.3764 - acc: 0.8388\n",
    "Epoch 4/10\n",
    "30000/30000 [==============================] - 49s 2ms/step - loss: 0.2909 - acc: 0.8826\n",
    "Epoch 5/10\n",
    "30000/30000 [==============================] - 49s 2ms/step - loss: 0.2161 - acc: 0.9213\n",
    "Epoch 6/10\n",
    "30000/30000 [==============================] - 49s 2ms/step - loss: 0.1480 - acc: 0.9505\n",
    "Epoch 7/10\n",
    "30000/30000 [==============================] - 49s 2ms/step - loss: 0.1031 - acc: 0.9679\n",
    "Epoch 8/10\n",
    "30000/30000 [==============================] - 49s 2ms/step - loss: 0.0750 - acc: 0.9777\n",
    "Epoch 9/10\n",
    "30000/30000 [==============================] - 49s 2ms/step - loss: 0.0568 - acc: 0.9843\n",
    "Epoch 10/10\n",
    "30000/30000 [==============================] - 49s 2ms/step - loss: 0.0492 - acc: 0.9854\n",
    "100/100 [==============================] - 8s 82ms/step\n",
    "0.5552593660354614\n",
    "0.81\n",
    "1.0574453\n",
    "0.61\n",
    "Train batch size32 of 40000 run:\n",
    "Epoch 1/10\n",
    "40000/40000 [==============================] - 476s 12ms/step - loss: 0.6072 - acc: 0.6638\n",
    "Epoch 2/10\n",
    "40000/40000 [==============================] - 449s 11ms/step - loss: 0.5250 - acc: 0.7395\n",
    "Epoch 3/10\n",
    "40000/40000 [==============================] - 442s 11ms/step - loss: 0.4855 - acc: 0.7674\n",
    "Epoch 4/10\n",
    "40000/40000 [==============================] - 442s 11ms/step - loss: 0.4520 - acc: 0.7871\n",
    "Epoch 5/10\n",
    "40000/40000 [==============================] - 442s 11ms/step - loss: 0.4318 - acc: 0.8011\n",
    "Epoch 6/10\n",
    "40000/40000 [==============================] - 442s 11ms/step - loss: 0.4081 - acc: 0.8145\n",
    "Epoch 7/10\n",
    "40000/40000 [==============================] - 442s 11ms/step - loss: 0.3972 - acc: 0.8228\n",
    "Epoch 8/10\n",
    "40000/40000 [==============================] - 442s 11ms/step - loss: 0.3772 - acc: 0.8331\n",
    "Epoch 9/10\n",
    "40000/40000 [==============================] - 442s 11ms/step - loss: 0.3632 - acc: 0.8398\n",
    "Epoch 10/10\n",
    "40000/40000 [==============================] - 442s 11ms/step - loss: 0.3430 - acc: 0.8512\n",
    "100/100 [==============================] - 8s 84ms/step\n",
    "0.41207624673843385\n",
    "0.82\n",
    "0.71522325\n",
    "0.66\n",
    "Train batch size64 of 40000 run:\n",
    "Epoch 1/10\n",
    "40000/40000 [==============================] - 259s 6ms/step - loss: 0.5939 - acc: 0.6750\n",
    "Epoch 2/10\n",
    "40000/40000 [==============================] - 238s 6ms/step - loss: 0.4998 - acc: 0.7578\n",
    "Epoch 3/10\n",
    "40000/40000 [==============================] - 238s 6ms/step - loss: 0.4579 - acc: 0.7831\n",
    "Epoch 4/10\n",
    "40000/40000 [==============================] - 238s 6ms/step - loss: 0.4241 - acc: 0.8068\n",
    "Epoch 5/10\n",
    "40000/40000 [==============================] - 238s 6ms/step - loss: 0.3924 - acc: 0.8235\n",
    "Epoch 6/10\n",
    "40000/40000 [==============================] - 238s 6ms/step - loss: 0.3644 - acc: 0.8399\n",
    "Epoch 7/10\n",
    "40000/40000 [==============================] - 238s 6ms/step - loss: 0.3425 - acc: 0.8520\n",
    "Epoch 8/10\n",
    "40000/40000 [==============================] - 246s 6ms/step - loss: 0.3199 - acc: 0.8642\n",
    "Epoch 9/10\n",
    "40000/40000 [==============================] - 246s 6ms/step - loss: 0.2992 - acc: 0.8732\n",
    "Epoch 10/10\n",
    "40000/40000 [==============================] - 246s 6ms/step - loss: 0.2818 - acc: 0.8808\n",
    "100/100 [==============================] - 9s 87ms/step\n",
    "0.3994665062427521\n",
    "0.79\n",
    "0.63927424\n",
    "0.71\n",
    "Train batch size128 of 40000 run:\n",
    "Epoch 1/10\n",
    "40000/40000 [==============================] - 161s 4ms/step - loss: 0.5802 - acc: 0.6873\n",
    "Epoch 2/10\n",
    "40000/40000 [==============================] - 140s 4ms/step - loss: 0.4683 - acc: 0.7793\n",
    "Epoch 3/10\n",
    "40000/40000 [==============================] - 140s 3ms/step - loss: 0.4066 - acc: 0.8162\n",
    "Epoch 4/10\n",
    "40000/40000 [==============================] - 140s 3ms/step - loss: 0.3579 - acc: 0.8430\n",
    "Epoch 5/10\n",
    "40000/40000 [==============================] - 140s 3ms/step - loss: 0.3223 - acc: 0.8602\n",
    "Epoch 6/10\n",
    "40000/40000 [==============================] - 140s 3ms/step - loss: 0.2871 - acc: 0.8801\n",
    "Epoch 7/10\n",
    "40000/40000 [==============================] - 140s 3ms/step - loss: 0.2604 - acc: 0.8922\n",
    "Epoch 8/10\n",
    "40000/40000 [==============================] - 140s 3ms/step - loss: 0.2343 - acc: 0.9042\n",
    "Epoch 9/10\n",
    "40000/40000 [==============================] - 140s 3ms/step - loss: 0.2129 - acc: 0.9125\n",
    "Epoch 10/10\n",
    "40000/40000 [==============================] - 140s 3ms/step - loss: 0.1900 - acc: 0.9236\n",
    "100/100 [==============================] - 9s 89ms/step\n",
    "0.26791083335876464\n",
    "0.88\n",
    "0.7879113\n",
    "0.67\n",
    "Train batch size256 of 40000 run:\n",
    "Epoch 1/10\n",
    "40000/40000 [==============================] - 115s 3ms/step - loss: 0.5730 - acc: 0.6971\n",
    "Epoch 2/10\n",
    "40000/40000 [==============================] - 92s 2ms/step - loss: 0.4446 - acc: 0.7932\n",
    "Epoch 3/10\n",
    "40000/40000 [==============================] - 93s 2ms/step - loss: 0.3775 - acc: 0.8336\n",
    "Epoch 4/10\n",
    "40000/40000 [==============================] - 93s 2ms/step - loss: 0.3189 - acc: 0.8634\n",
    "Epoch 5/10\n",
    "40000/40000 [==============================] - 92s 2ms/step - loss: 0.2676 - acc: 0.8916\n",
    "Epoch 6/10\n",
    "40000/40000 [==============================] - 93s 2ms/step - loss: 0.2207 - acc: 0.9126\n",
    "Epoch 7/10\n",
    "40000/40000 [==============================] - 93s 2ms/step - loss: 0.1856 - acc: 0.9265\n",
    "Epoch 8/10\n",
    "40000/40000 [==============================] - 93s 2ms/step - loss: 0.1594 - acc: 0.9384\n",
    "Epoch 9/10\n",
    "40000/40000 [==============================] - 93s 2ms/step - loss: 0.1323 - acc: 0.9492\n",
    "Epoch 10/10\n",
    "40000/40000 [==============================] - 93s 2ms/step - loss: 0.1115 - acc: 0.9580\n",
    "100/100 [==============================] - 9s 91ms/step\n",
    "0.46700154304504393\n",
    "0.82\n",
    "0.9349997\n",
    "0.68\n",
    "Train batch size512 of 40000 run:\n",
    "Epoch 1/10\n",
    "40000/40000 [==============================] - 88s 2ms/step - loss: 0.5989 - acc: 0.6713\n",
    "Epoch 2/10\n",
    "40000/40000 [==============================] - 66s 2ms/step - loss: 0.4502 - acc: 0.7947\n",
    "Epoch 3/10\n",
    "40000/40000 [==============================] - 66s 2ms/step - loss: 0.3708 - acc: 0.8416\n",
    "Epoch 4/10\n",
    "40000/40000 [==============================] - 66s 2ms/step - loss: 0.3025 - acc: 0.8750\n",
    "Epoch 5/10\n",
    "40000/40000 [==============================] - 66s 2ms/step - loss: 0.2379 - acc: 0.9076\n",
    "Epoch 6/10\n",
    "40000/40000 [==============================] - 66s 2ms/step - loss: 0.1820 - acc: 0.9336\n",
    "Epoch 7/10\n",
    "40000/40000 [==============================] - 66s 2ms/step - loss: 0.1372 - acc: 0.9510\n",
    "Epoch 8/10\n",
    "40000/40000 [==============================] - 66s 2ms/step - loss: 0.1009 - acc: 0.9670\n",
    "Epoch 9/10\n",
    "40000/40000 [==============================] - 66s 2ms/step - loss: 0.0821 - acc: 0.9728\n",
    "Epoch 10/10\n",
    "40000/40000 [==============================] - 66s 2ms/step - loss: 0.0664 - acc: 0.9786\n",
    "100/100 [==============================] - 9s 94ms/step\n",
    "0.4369861698150635\n",
    "0.86\n",
    "0.9209289\n",
    "0.62\n",
    "Train batch size32 of 50000 run:\n",
    "Epoch 1/10\n",
    "50000/50000 [==============================] - 594s 12ms/step - loss: 0.5929 - acc: 0.6782\n",
    "Epoch 2/10\n",
    "50000/50000 [==============================] - 571s 11ms/step - loss: 0.5108 - acc: 0.7502\n",
    "Epoch 3/10\n",
    "50000/50000 [==============================] - 571s 11ms/step - loss: 0.4704 - acc: 0.7771\n",
    "Epoch 4/10\n",
    "50000/50000 [==============================] - 571s 11ms/step - loss: 0.4436 - acc: 0.7922\n",
    "Epoch 5/10\n",
    "50000/50000 [==============================] - 571s 11ms/step - loss: 0.4169 - acc: 0.8075\n",
    "Epoch 6/10\n",
    "50000/50000 [==============================] - 571s 11ms/step - loss: 0.3916 - acc: 0.8232\n",
    "Epoch 7/10\n",
    "50000/50000 [==============================] - 571s 11ms/step - loss: 0.3699 - acc: 0.8350\n",
    "Epoch 8/10\n",
    "50000/50000 [==============================] - 571s 11ms/step - loss: 0.3540 - acc: 0.8441\n",
    "Epoch 9/10\n",
    "50000/50000 [==============================] - 571s 11ms/step - loss: 0.3358 - acc: 0.8530\n",
    "Epoch 10/10\n",
    "50000/50000 [==============================] - 571s 11ms/step - loss: 0.3229 - acc: 0.8602\n",
    "100/100 [==============================] - 10s 101ms/step\n",
    "0.3675303053855896\n",
    "0.85\n",
    "0.6291935\n",
    "0.73\n",
    "Train batch size64 of 50000 run:\n",
    "Epoch 1/10\n",
    "50000/50000 [==============================] - 332s 7ms/step - loss: 0.5715 - acc: 0.6994\n",
    "Epoch 2/10\n",
    "50000/50000 [==============================] - 308s 6ms/step - loss: 0.4821 - acc: 0.7707\n",
    "Epoch 3/10\n",
    "50000/50000 [==============================] - 308s 6ms/step - loss: 0.4347 - acc: 0.8002\n",
    "Epoch 4/10\n",
    "50000/50000 [==============================] - 308s 6ms/step - loss: 0.4009 - acc: 0.8182\n",
    "Epoch 5/10\n",
    "50000/50000 [==============================] - 308s 6ms/step - loss: 0.3658 - acc: 0.8388\n",
    "Epoch 6/10\n",
    "50000/50000 [==============================] - 308s 6ms/step - loss: 0.3408 - acc: 0.8523\n",
    "Epoch 7/10\n",
    "50000/50000 [==============================] - 308s 6ms/step - loss: 0.3195 - acc: 0.8616\n",
    "Epoch 8/10\n",
    "50000/50000 [==============================] - 308s 6ms/step - loss: 0.2979 - acc: 0.8752\n",
    "Epoch 9/10\n",
    "50000/50000 [==============================] - 308s 6ms/step - loss: 0.2832 - acc: 0.8801\n",
    "Epoch 10/10\n",
    "50000/50000 [==============================] - 308s 6ms/step - loss: 0.2681 - acc: 0.8880\n",
    "100/100 [==============================] - 10s 102ms/step\n",
    "0.3567990040779114\n",
    "0.84\n",
    "0.95313257\n",
    "0.56\n",
    "Train batch size128 of 50000 run:\n",
    "Epoch 1/10\n",
    "50000/50000 [==============================] - 199s 4ms/step - loss: 0.5619 - acc: 0.7026\n",
    "Epoch 2/10\n",
    "50000/50000 [==============================] - 175s 3ms/step - loss: 0.4544 - acc: 0.7889\n",
    "Epoch 3/10\n",
    "50000/50000 [==============================] - 174s 3ms/step - loss: 0.3997 - acc: 0.8187\n",
    "Epoch 4/10\n",
    "50000/50000 [==============================] - 175s 3ms/step - loss: 0.3559 - acc: 0.8434\n",
    "Epoch 5/10\n",
    "50000/50000 [==============================] - 175s 3ms/step - loss: 0.3212 - acc: 0.8616\n",
    "Epoch 6/10\n",
    "50000/50000 [==============================] - 175s 3ms/step - loss: 0.2903 - acc: 0.8777\n",
    "Epoch 7/10\n",
    "50000/50000 [==============================] - 175s 3ms/step - loss: 0.2610 - acc: 0.8918\n",
    "Epoch 8/10\n",
    "50000/50000 [==============================] - 174s 3ms/step - loss: 0.2373 - acc: 0.9028\n",
    "Epoch 9/10\n",
    "50000/50000 [==============================] - 175s 3ms/step - loss: 0.2173 - acc: 0.9119\n",
    "Epoch 10/10\n",
    "50000/50000 [==============================] - 175s 3ms/step - loss: 0.2010 - acc: 0.9187\n",
    "100/100 [==============================] - 10s 104ms/step\n",
    "0.3128787899017334\n",
    "0.84\n",
    "0.62127125\n",
    "0.72\n",
    "Train batch size256 of 50000 run:\n",
    "Epoch 1/10\n",
    "50000/50000 [==============================] - 140s 3ms/step - loss: 0.5575 - acc: 0.7092\n",
    "Epoch 2/10\n",
    "50000/50000 [==============================] - 116s 2ms/step - loss: 0.4249 - acc: 0.8068\n",
    "Epoch 3/10\n",
    "50000/50000 [==============================] - 115s 2ms/step - loss: 0.3522 - acc: 0.8464\n",
    "Epoch 4/10\n",
    "50000/50000 [==============================] - 116s 2ms/step - loss: 0.2944 - acc: 0.8772\n",
    "Epoch 5/10\n",
    "50000/50000 [==============================] - 115s 2ms/step - loss: 0.2497 - acc: 0.8972\n",
    "Epoch 6/10\n",
    "50000/50000 [==============================] - 116s 2ms/step - loss: 0.2121 - acc: 0.9159\n",
    "Epoch 7/10\n",
    "50000/50000 [==============================] - 116s 2ms/step - loss: 0.1806 - acc: 0.9285\n",
    "Epoch 8/10\n",
    "50000/50000 [==============================] - 115s 2ms/step - loss: 0.1541 - acc: 0.9404\n",
    "Epoch 9/10\n",
    "50000/50000 [==============================] - 116s 2ms/step - loss: 0.1340 - acc: 0.9480\n",
    "Epoch 10/10\n",
    "50000/50000 [==============================] - 115s 2ms/step - loss: 0.1163 - acc: 0.9559\n",
    "100/100 [==============================] - 11s 107ms/step\n",
    "0.40484333395957944\n",
    "0.87\n",
    "1.2858269\n",
    "0.6\n",
    "Train batch size512 of 50000 run:\n",
    "Epoch 1/10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
