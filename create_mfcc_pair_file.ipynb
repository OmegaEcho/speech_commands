{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a notebook to generate mfcc features for audio, features will be save to a binary file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import hashlib\n",
    "import math, time, datetime\n",
    "import os.path\n",
    "import random\n",
    "import re\n",
    "import sys\n",
    "import tarfile\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import librosa as rosa\n",
    "import librosa.display\n",
    "from six.moves import urllib\n",
    "from six.moves import xrange  # pylint: disable=redefined-builtin\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "\n",
    "default_number_of_mfcc=128\n",
    "default_sample_rate=16000\n",
    "default_hop_length=512 \n",
    "default_wav_duration=1 # 1 second\n",
    "default_validation_percentage=0.01\n",
    "default_train_samples=50000\n",
    "default_validation_samples=100\n",
    "default_test_samples=100\n",
    "default_wanted_words=[\"one\", \"two\", \"bed\", \"backward\", \"bird\", \"cat\", \"dog\", \"eight\", \"five\", \"follow\", \"forward\", \"four\", \"go\", \"happy\", \"house\", \"learn\", \"left\", \"marvin\", \"nine\", \"no\", \"off\", \"right\", \"seven\", \"sheila\", \"stop\", \"three\", \"tree\", \"visual\", \"wow\", \"zero\",\"up\"]\n",
    "default_train_words=[\"one\", \"two\", \"cat\", \"dog\", \"bed\", \"backward\", \"eight\",\"forward\", \"four\", \"go\", \"happy\", \"house\", \"learn\", \"left\", \"marvin\", \"nine\", \"no\", \"off\", \"right\", \"seven\", \"sheila\", \"stop\", \"three\", \"tree\", \"visual\", \"wow\", \"zero\",\"up\"]\n",
    "default_test_words=[\"five\", \"follow\", \"bird\"]\n",
    "\n",
    "#STUB start\n",
    "#default_wanted_words=[\"stub1\", \"stub2\"]\n",
    "#default_train_words=[\"stub1\", \"stub2\"]\n",
    "#default_test_words=[\"stub2\"]\n",
    "#default_validation_percentage=0.5\n",
    "#STUB end\n",
    "\n",
    "#for linux\n",
    "speech_data_dir=\"/home/zhangjun/tensorflow/speech_siamese_zj/speech_dataset\"\n",
    "\n",
    "#for windows\n",
    "#speech_data_dir=\"D:\\jun\\speech_commands-master\\dataset\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One shot keyword trigger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Here is another implementation of one-shot learning of keyword trigger with librosa mfcc. \n",
    "librosa cannot put into tensorflow graph. so mfcc computation will be done before conv network. \n",
    "that means load_wav_mfcc has to convert all wav file to mfcc vector. \n",
    "Here i have to understand\n",
    "    1, what is the good mfcc vector dimension. 20, 127 may not be the right input for conv network. \n",
    "    2, even the mfcc output of librosa is not the same as tensorflow contrib.decode wav, it is enough if it has all audio feature. put librosa mfcc output as input of conv net, it will do good learning about feature abstraction. \n",
    "    3, conv net may not be that difficult. just like conv2d -> maxpooling -> conv2d->flatten->dense with softmax. \n",
    "    4, build the train network with librosa and conv net.\n",
    "    5, take the dense vector output as feature extractor. \n",
    "    6, build siamese network with the feature extractor. \n",
    "    7, may add couples of dense layer to learn the feature mapping and comparation of siamese. \n",
    "    8, if that works, we get an one-shot learning for key word trigger...\n",
    "    9, in reality, we still have to work out how to split the audio stream into audio clip as the input the librosa mfcc.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MFCC "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "extract MFCC from wav file\n",
    "what is the wav parameter for MFCC output\n",
    "\n",
    "tensorflow speech command parameter \n",
    "{'desired_samples': 16000, 'window_size_samples': 480, 'window_stride_samples': 160, 'spectrogram_length': 98, 'fingerprint_width': 40, 'fingerprint_size': 3920, 'label_count': 12, 'sample_rate': 16000, 'preprocess': 'mfcc', 'average_window_width': -1}\n",
    "\n",
    "Mel-frequency cepstral coefficients (MFCCs)\n",
    "Parameters:\t\n",
    "y:np.ndarray [shape=(n,)] or None\n",
    "audio time series\n",
    "sr:number > 0 [scalar]\n",
    "sampling rate of y\n",
    "S:np.ndarray [shape=(d, t)] or None\n",
    "log-power Mel spectrogram\n",
    "n_mfcc: int > 0 [scalar]\n",
    "number of MFCCs to return\n",
    "Returns:\t\n",
    "M:np.ndarray [shape=(n_mfcc, t)]\n",
    "MFCC sequence\n",
    "\n",
    "need more study about MFCC output\n",
    "\n",
    "\n",
    "## How to calculate the lenght of mfcc vector\n",
    "Short Answer\n",
    "\n",
    "You can specify the change the length by changing the parameters used in the stft calculations. The following code will double the size of your output (20 x 113658)\n",
    "\n",
    "data = librosa.feature.mfcc(y=y, sr=sr, n_fft=1012, hop_length=256, n_mfcc=20)\n",
    "Long Answer\n",
    "\n",
    "Librosa's librosa.feature.mfcc() function really just acts as a wrapper to librosa's librosa.feature.melspectrogram() function (which is a wrapper to librosa.core.stft and librosa.filters.mel functions).\n",
    "\n",
    "All of the parameters pertaining to segementation of the audio signal - namely the frame and overlap values - are specified utilized in the Mel-scaled power spectrogram function (with other tune-able parameters specified for nested core functions). You specify these parameters as keyword arguments in the librosa.feature.mfcc() function.\n",
    "\n",
    "All extra **kwargs parameters are fed to librosa.feature.melspectrogram() and subsequently to librosa.filters.mel()\n",
    "\n",
    "By Default, the Mel-scaled power spectrogram window and hop length are the following:\n",
    "\n",
    "n_fft=2048\n",
    "\n",
    "hop_length=512\n",
    "\n",
    "So assuming you used the default sample rate (sr=22050), the output of your mfcc function makes sense:\n",
    "\n",
    "output length = (seconds) * (sample rate) / (hop_length)\n",
    "\n",
    "(1319) * (22050) / (512) = 56804 samples\n",
    "\n",
    "\n",
    "the mfcc vector size is 128 * 32   \n",
    "\n",
    "1 * 16000/512 = 31.25 = 32 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_wav_mfcc(filename):\n",
    "    wav_loader, sample_rate = rosa.load(filename, sr=default_sample_rate)\n",
    "    #print(rosa.get_duration(wav_loader, sample_rate))\n",
    "    wav_mfcc = rosa.feature.mfcc(y=wav_loader, sr=default_sample_rate, n_mfcc=default_number_of_mfcc)\n",
    "    wav_mfcc = np.transpose(wav_mfcc)\n",
    "    return wav_mfcc\n",
    "\n",
    "def get_default_mfcc_length(default_wav_duration=1):\n",
    "    length = int(math.ceil(default_wav_duration * default_sample_rate / default_hop_length))\n",
    "    return length\n",
    "\n",
    "def mfcc_display(mfccs):\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    librosa.display.specshow(mfccs, x_axis='time')\n",
    "    plt.colorbar()\n",
    "    plt.title('MFCC')\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wav MFCC loader\n",
    "Wav file loader and export mfcc sequence. \n",
    "\n",
    "0, go throught all wav file to add background voice into command wav file\n",
    "1, go through all wav file and convert to MFCC sequence\n",
    "2, construct pair of MFCC sequence and a target (0 or 1, 0 for different command, 1 for the same command)\n",
    "    the same word * 1000, random generate key index, the first index of wav, and the second index of wav. \n",
    "    the diff word * 1000, random generae two key index, the first index of wav, and the second index of wav. \n",
    "    the format will be [mfcc 1, mfcc 2, 0/1 for the same or different]\n",
    "3, prepare pair of MFCC and targets according to batch size.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WavMFCCLoader(object):\n",
    "    def __init__(self, data_dir, wanted, mean=0, std=0):\n",
    "        self.data_dir = data_dir\n",
    "        self.wanted = wanted\n",
    "        self.default_mfcc_length=get_default_mfcc_length(default_wav_duration)\n",
    "        self.wav_files = dict()\n",
    "        self.train_wav_files = dict()\n",
    "        self.validation_wav_files = dict()\n",
    "        self.wav_file_index()\n",
    "        self.train_validation_wav_file_index()\n",
    "        self.mfcc_mean = mean\n",
    "        self.mfcc_std = std\n",
    "        #print(\"train_wav_files:\", self.train_wav_files)\n",
    "        #print(\"validation_wav_files:\", self.validation_wav_files)\n",
    "        \n",
    "    def wav_file_index(self):\n",
    "        for dirpath, dirnames, files in os.walk(self.data_dir):\n",
    "            for name in files:\n",
    "                if name.lower().endswith('.wav'):\n",
    "                    #for windows\n",
    "                    #word_name = dirpath.rsplit('\\\\', 1)[1];\n",
    "                    #for others\n",
    "                    word_name = dirpath.rsplit('/', 1)[1];\n",
    "                    if word_name in self.wanted:\n",
    "                        file_name = os.path.join(dirpath, name)\n",
    "                        #print(file_name, dirpath, word_name)\n",
    "    \n",
    "                        if word_name in self.wav_files.keys():\n",
    "                            self.wav_files[word_name].append(file_name)\n",
    "                        else:\n",
    "                            self.wav_files[word_name] = [file_name]\n",
    "                    \n",
    "        return self.wav_files\n",
    "    \n",
    "    def train_validation_wav_file_index(self):\n",
    "        for i in (self.wanted):\n",
    "            wav_num = len(self.wav_files[i])\n",
    "            wav_validation_num = int(wav_num * default_validation_percentage)\n",
    "            wav_train_num = wav_num - wav_validation_num\n",
    "            #print(\"wav_train_num:\", wav_train_num)\n",
    "            #print(\"wav_validation_num:\", wav_validation_num)\n",
    "            \n",
    "            self.train_wav_files[i] = [self.wav_files[i][0]]\n",
    "            self.validation_wav_files[i] = [self.wav_files[i][wav_train_num]]\n",
    "            \n",
    "            for j in range(1, wav_train_num):\n",
    "                self.train_wav_files[i].append(self.wav_files[i][j])\n",
    "                \n",
    "            for j in range(wav_train_num + 1, wav_num):\n",
    "                self.validation_wav_files[i].append(self.wav_files[i][j])\n",
    "                \n",
    "        return self.train_wav_files, self.validation_wav_files\n",
    "    \n",
    "    def wavs_to_mfcc_pair(self, wav_files = dict()):\n",
    "        how_many_words = len(self.wanted)\n",
    "        a_index = random.randint(0, how_many_words - 1)\n",
    "        b_index = random.randint(0, how_many_words - 1)\n",
    " \n",
    "        a_wav_index = b_wav_index = -1\n",
    "        if (a_index > b_index):\n",
    "            a_wav_index = random.randint(0, len(wav_files[self.wanted[a_index]]) - 1)\n",
    "            b_wav_index = random.randint(0, len(wav_files[self.wanted[b_index]]) - 1)\n",
    "            mfcc_1 = load_wav_mfcc(wav_files[self.wanted[a_index]][a_wav_index])\n",
    "            mfcc_2 = load_wav_mfcc(wav_files[self.wanted[b_index]][b_wav_index])\n",
    "            mfcc_pair = 0            \n",
    "        else:\n",
    "            a_wav_index = random.randint(0, len(wav_files[self.wanted[a_index]]) - 1)\n",
    "            b_wav_index = random.randint(0, len(wav_files[self.wanted[a_index]]) - 1)\n",
    "            mfcc_1 = load_wav_mfcc(wav_files[self.wanted[a_index]][a_wav_index])\n",
    "            mfcc_2 = load_wav_mfcc(wav_files[self.wanted[a_index]][b_wav_index])\n",
    "            mfcc_pair = 1\n",
    "               \n",
    "        return mfcc_1, mfcc_2, mfcc_pair\n",
    "        \n",
    "    def get_mfcc_pairs(self, how_many, period = \"train\", preprocess = \"global\"):\n",
    "        mfcc1_data = np.zeros((how_many, self.default_mfcc_length, default_number_of_mfcc))\n",
    "        mfcc2_data = np.zeros((how_many, self.default_mfcc_length, default_number_of_mfcc))\n",
    "        same_data = np.zeros(how_many)\n",
    "            \n",
    "        for i in range(0, how_many):\n",
    "            if period == \"train\":\n",
    "                mfcc1_data_, mfcc2_data_, same_data[i] = self.wavs_to_mfcc_pair(wav_files = self.train_wav_files)\n",
    "            elif period == \"validate\":\n",
    "                mfcc1_data_, mfcc2_data_, same_data[i] = self.wavs_to_mfcc_pair(wav_files = self.validation_wav_files)\n",
    "            elif period == \"test\":\n",
    "                mfcc1_data_, mfcc2_data_, same_data[i] = self.wavs_to_mfcc_pair(wav_files = self.wav_files)\n",
    "            else:\n",
    "                raise ValueError(\"unknown period\")\n",
    "                       \n",
    "            \n",
    "            if preprocess == \"global\":\n",
    "                mfcc1_data_ = (mfcc1_data_ - self.mfcc_mean[0:mfcc1_data_.shape[0], :]) / self.mfcc_std[0:mfcc1_data_.shape[0], :]\n",
    "                mfcc2_data_ = (mfcc2_data_ - self.mfcc_mean[0:mfcc2_data_.shape[0], :]) / self.mfcc_std[0:mfcc2_data_.shape[0], :]\n",
    "            elif preprocess == \"z-score\":\n",
    "                mfcc1_data_ = preprocessing.scale(mfcc1_data_)\n",
    "                mfcc2_data_ = preprocessing.scale(mfcc2_data_)               \n",
    "            elif preprocess == \"max-min-scaler\":\n",
    "                mfcc1_data_ = preprocessing.MinMaxScaler().fit_transform(mfcc1_data_)\n",
    "                mfcc2_data_ = preprocessing.MinMaxScaler().fit_transform(mfcc2_data_)\n",
    "            elif preprocess == \"l2-normalize\":\n",
    "                mfcc1_data_ = preprocessing.normalize(mfcc1_data_, norm='l2')\n",
    "                mfcc2_data_ = preprocessing.normalize(mfcc2_data_, norm='l2')\n",
    "            else:\n",
    "                raise ValueError(\"unknown proprocess\")\n",
    "                \n",
    "            mfcc1_data[i, 0:mfcc1_data_.shape[0], : ] = mfcc1_data_\n",
    "            mfcc2_data[i, 0:mfcc2_data_.shape[0], : ] = mfcc2_data_\n",
    "    \n",
    "        return mfcc1_data, mfcc2_data, same_data \n",
    "    \n",
    "    def get_sample_mean_std(self):\n",
    "        count = 0\n",
    "        for i in (self.wanted):\n",
    "            #print(i)\n",
    "            for j in range(len(self.wav_files[i])):\n",
    "                #print(self.wav_files[i][j])\n",
    "                count += 1\n",
    "        #print(\"count:\", count)\n",
    "        mfccs = np.zeros((count, self.default_mfcc_length, default_number_of_mfcc))\n",
    "        index = 0\n",
    "        for i in (self.wanted):\n",
    "            for j in range(len(self.wav_files[i])):       \n",
    "                mfcc_ = load_wav_mfcc(self.wav_files[i][j])\n",
    "                mfccs[index, 0:mfcc_.shape[0], : ] = mfcc_\n",
    "                index += 1\n",
    "        #print(\"mfccs.shape:\", mfccs.shape)\n",
    "        return mfccs.mean(0), mfccs.std(0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# mean & std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader_1 = WavMFCCLoader(speech_data_dir, wanted=default_wanted_words)\n",
    "mfcc_mean, mfcc_std = loader_1.get_sample_mean_std()\n",
    "\n",
    "#save to binary file\n",
    "file_mean = \"binary_data/\"+\"mfcc_mean_\" + str(mfcc_mean.shape) + \"_\" + str(datetime.date.today()) + \".npy\"\n",
    "print(file_mean)\n",
    "f = open(file_mean, \"wb\")\n",
    "np.save(f, mfcc_mean)\n",
    "f.close()\n",
    "\n",
    "file_std = \"binary_data/\"+\"mfcc_std_\" + str(mfcc_std.shape) + \"_\" + str(datetime.date.today()) + \".npy\"\n",
    "print(file_std)\n",
    "f = open(file_std, \"wb\")\n",
    "np.save(f, mfcc_std)\n",
    "f.close()\n",
    "\n",
    "#f = open(file_mean, \"rb\")\n",
    "#t = np.load(f)\n",
    "#print(\"mean shape:\", t.shape)\n",
    "#mfcc_display(np.transpose(t))\n",
    "#f.close()\n",
    "\n",
    "#f = open(file_std, \"rb\")\n",
    "#t = np.load(f)\n",
    "#print(\"std shape:\", t.shape)\n",
    "#mfcc_display(np.transpose(t))\n",
    "#f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train data: global"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader_2 = WavMFCCLoader(speech_data_dir, wanted=default_train_words, mean = mfcc_mean, std = mfcc_std)\n",
    "mfcc1_train_global, mfcc2_train_global, same_train_global = loader_2.get_mfcc_pairs(default_train_samples, period = \"train\", preprocess = \"global\")\n",
    "\n",
    "#save to binary file\n",
    "path = \"binary_data/train_global/\"\n",
    "file_mfcc1 = path+\"mfcc1_train_global_\" + str(mfcc1_train_global.shape) + \"_\" + str(datetime.date.today()) + \".npy\"\n",
    "print(file_mfcc1)\n",
    "f = open(file_mfcc1, \"wb\")\n",
    "np.save(f, mfcc1_train_global)\n",
    "f.close()\n",
    "\n",
    "file_mfcc2 = path+\"mfcc2_train_global_\" + str(mfcc2_train_global.shape) + \"_\" + str(datetime.date.today()) + \".npy\"\n",
    "print(file_mfcc2)\n",
    "f = open(file_mfcc2, \"wb\")\n",
    "np.save(f, mfcc2_train_global)\n",
    "f.close()\n",
    "\n",
    "file_label = path+\"label_train_global_\" + str(same_train_global.shape) + \"_\" + str(datetime.date.today()) + \".npy\"\n",
    "print(file_label)\n",
    "f = open(file_label, \"wb\")\n",
    "np.save(f, same_train_global)\n",
    "f.close()\n",
    "\n",
    "#f = open(file_label, \"rb\")\n",
    "#t = np.load(f)\n",
    "#print(\"shape:\", t.shape)\n",
    "#for i in range(len(t)):\n",
    "    #mfcc_display(np.transpose(t[i]))\n",
    "    #print(t[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train data: z-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mfcc1_train_z, mfcc2_train_z, same_train_z = loader_2.get_mfcc_pairs(default_train_samples, period = \"train\", preprocess = \"z-score\")\n",
    "\n",
    "#save to binary file\n",
    "path = \"binary_data/train_score/\"\n",
    "file_mfcc1 = path+\"mfcc1_train_score_\" + str(mfcc1_train_z.shape) + \"_\" + str(datetime.date.today()) + \".npy\"\n",
    "print(file_mfcc1)\n",
    "f = open(file_mfcc1, \"wb\")\n",
    "np.save(f, mfcc1_train_z)\n",
    "f.close()\n",
    "\n",
    "file_mfcc2 = path+\"mfcc2_train_score_\" + str(mfcc2_train_z.shape) + \"_\" + str(datetime.date.today()) + \".npy\"\n",
    "print(file_mfcc2)\n",
    "f = open(file_mfcc2, \"wb\")\n",
    "np.save(f, mfcc2_train_z)\n",
    "f.close()\n",
    "\n",
    "file_label = path+\"label_train_score_\" + str(same_train_z.shape) + \"_\" + str(datetime.date.today()) + \".npy\"\n",
    "print(file_label)\n",
    "f = open(file_label, \"wb\")\n",
    "np.save(f, same_train_z)\n",
    "f.close()\n",
    "\n",
    "#f = open(file_label, \"rb\")\n",
    "#t = np.load(f)\n",
    "#print(\"shape:\", t.shape)\n",
    "#for i in range(len(t)):\n",
    "    #mfcc_display(np.transpose(t[i]))\n",
    "    #print(t[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train data: max-min-scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mfcc1_train_s, mfcc2_train_s, same_train_s = loader_2.get_mfcc_pairs(default_train_samples, period = \"train\", preprocess = \"max-min-scaler\")\n",
    "\n",
    "#save to binary file\n",
    "path = \"binary_data/train_scaler/\"\n",
    "file_mfcc1 = path+\"mfcc1_train_scaler_\" + str(mfcc1_train_s.shape) + \"_\" + str(datetime.date.today()) + \".npy\"\n",
    "print(file_mfcc1)\n",
    "f = open(file_mfcc1, \"wb\")\n",
    "np.save(f, mfcc1_train_s)\n",
    "f.close()\n",
    "\n",
    "file_mfcc2 = path+\"mfcc2_train_scaler_\" + str(mfcc2_train_s.shape) + \"_\" + str(datetime.date.today()) + \".npy\"\n",
    "print(file_mfcc2)\n",
    "f = open(file_mfcc2, \"wb\")\n",
    "np.save(f, mfcc2_train_s)\n",
    "f.close()\n",
    "\n",
    "file_label = path+\"label_train_scaler_\" + str(same_train_s.shape) + \"_\" + str(datetime.date.today()) + \".npy\"\n",
    "print(file_label)\n",
    "f = open(file_label, \"wb\")\n",
    "np.save(f, same_train_s)\n",
    "f.close()\n",
    "\n",
    "#f = open(file_mfcc2, \"rb\")\n",
    "#t = np.load(f)\n",
    "#print(\"shape:\", t.shape)\n",
    "#for i in range(len(t)):\n",
    "    #mfcc_display(np.transpose(t[i]))\n",
    "    #print(t[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train data: l2-normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mfcc1_train_n, mfcc2_train_n, same_train_n = loader_2.get_mfcc_pairs(default_train_samples, period = \"train\", preprocess = \"l2-normalize\")\n",
    "\n",
    "#save to binary file\n",
    "path = \"binary_data/train_normalize/\"\n",
    "file_mfcc1 = path+\"mfcc1_train_normalize_\" + str(mfcc1_train_n.shape) + \"_\" + str(datetime.date.today()) + \".npy\"\n",
    "print(file_mfcc1)\n",
    "f = open(file_mfcc1, \"wb\")\n",
    "np.save(f, mfcc1_train_n)\n",
    "f.close()\n",
    "\n",
    "file_mfcc2 = path+\"mfcc2_train_normalize_\" + str(mfcc2_train_n.shape) + \"_\" + str(datetime.date.today()) + \".npy\"\n",
    "print(file_mfcc2)\n",
    "f = open(file_mfcc2, \"wb\")\n",
    "np.save(f, mfcc2_train_n)\n",
    "f.close()\n",
    "\n",
    "file_label = path+\"label_train_normalize_\" + str(same_train_n.shape) + \"_\" + str(datetime.date.today()) + \".npy\"\n",
    "print(file_label)\n",
    "f = open(file_label, \"wb\")\n",
    "np.save(f, same_train_n)\n",
    "f.close()\n",
    "\n",
    "\n",
    "#f = open(file_label, \"rb\")\n",
    "#t = np.load(f)\n",
    "#print(\"shape:\", t.shape)\n",
    "#for i in range(len(t)):\n",
    "    #mfcc_display(np.transpose(t[i]))\n",
    "    #print(t[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# validation data: global"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mfcc1_val_global, mfcc2_val_global, same_val_global = loader_2.get_mfcc_pairs(default_validation_samples, period = \"validate\", preprocess = \"global\")\n",
    "\n",
    "#save to binary file\n",
    "path = \"binary_data/validation_global/\"\n",
    "file_mfcc1 = path+\"mfcc1_validation_global_\" + str(mfcc1_val_global.shape) + \"_\" + str(datetime.date.today()) + \".npy\"\n",
    "print(file_mfcc1)\n",
    "f = open(file_mfcc1, \"wb\")\n",
    "np.save(f, mfcc1_val_global)\n",
    "f.close()\n",
    "\n",
    "file_mfcc2 = path+\"mfcc2_validation_global_\" + str(mfcc2_val_global.shape) + \"_\" + str(datetime.date.today()) + \".npy\"\n",
    "print(file_mfcc2)\n",
    "f = open(file_mfcc2, \"wb\")\n",
    "np.save(f, mfcc2_val_global)\n",
    "f.close()\n",
    "\n",
    "file_label = path+\"label_validation_global_\" + str(same_val_global.shape) + \"_\" + str(datetime.date.today()) + \".npy\"\n",
    "print(file_label)\n",
    "f = open(file_label, \"wb\")\n",
    "np.save(f, same_val_global)\n",
    "f.close()\n",
    "\n",
    "#f = open(file_mfcc2, \"rb\")\n",
    "#t = np.load(f)\n",
    "#print(\"shape:\", t.shape)\n",
    "#for i in range(len(t)):\n",
    "    #mfcc_display(np.transpose(t[i]))\n",
    "    #print(t[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# validation data: z-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mfcc1_val_score, mfcc2_val_score, same_val_score = loader_2.get_mfcc_pairs(default_validation_samples, period = \"validate\", preprocess = \"z-score\")\n",
    "\n",
    "#save to binary file\n",
    "path = \"binary_data/validation_score/\"\n",
    "file_mfcc1 = path+\"mfcc1_validation_score_\" + str(mfcc1_val_score.shape) + \"_\" + str(datetime.date.today()) + \".npy\"\n",
    "print(file_mfcc1)\n",
    "f = open(file_mfcc1, \"wb\")\n",
    "np.save(f, mfcc1_val_score)\n",
    "f.close()\n",
    "\n",
    "file_mfcc2 = path+\"mfcc2_validation_score_\" + str(mfcc2_val_score.shape) + \"_\" + str(datetime.date.today()) + \".npy\"\n",
    "print(file_mfcc2)\n",
    "f = open(file_mfcc2, \"wb\")\n",
    "np.save(f, mfcc2_val_score)\n",
    "f.close()\n",
    "\n",
    "file_label = path+\"label_validation_score_\" + str(same_val_score.shape) + \"_\" + str(datetime.date.today()) + \".npy\"\n",
    "print(file_label)\n",
    "f = open(file_label, \"wb\")\n",
    "np.save(f, same_val_score)\n",
    "f.close()\n",
    "\n",
    "#f = open(file_label, \"rb\")\n",
    "#t = np.load(f)\n",
    "#print(\"shape:\", t.shape)\n",
    "#for i in range(len(t)):\n",
    "    #mfcc_display(np.transpose(t[i]))\n",
    "    #print(t[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# validation data: max-min-scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mfcc1_val_scaler, mfcc2_val_scaler, same_val_scaler = loader_2.get_mfcc_pairs(default_validation_samples, period = \"validate\", preprocess = \"max-min-scaler\")\n",
    "#for i in range(len(mfcc1_train_global)):\n",
    "#    mfcc_display(np.transpose(mfcc1_train_global[i]))\n",
    "#    mfcc_display(np.transpose(mfcc2_train_global[i]))\n",
    "#    print(\"label:\", same_train_global[i])\n",
    "\n",
    "#save to binary file\n",
    "path = \"binary_data/validation_scaler/\"\n",
    "file_mfcc1 = path+\"mfcc1_validation_scaler_\" + str(mfcc1_val_scaler.shape) + \"_\" + str(datetime.date.today()) + \".npy\"\n",
    "print(file_mfcc1)\n",
    "f = open(file_mfcc1, \"wb\")\n",
    "np.save(f, mfcc1_val_scaler)\n",
    "f.close()\n",
    "\n",
    "file_mfcc2 = path+\"mfcc2_validation_scaler_\" + str(mfcc2_val_scaler.shape) + \"_\" + str(datetime.date.today()) + \".npy\"\n",
    "print(file_mfcc2)\n",
    "f = open(file_mfcc2, \"wb\")\n",
    "np.save(f, mfcc2_val_scaler)\n",
    "f.close()\n",
    "\n",
    "file_label = path+\"label_validation_scaler_\" + str(same_val_scaler.shape) + \"_\" + str(datetime.date.today()) + \".npy\"\n",
    "print(file_label)\n",
    "f = open(file_label, \"wb\")\n",
    "np.save(f, same_val_scaler)\n",
    "f.close()\n",
    "\n",
    "#f = open(file_mfcc2, \"rb\")\n",
    "#t = np.load(f)\n",
    "#print(\"shape:\", t.shape)\n",
    "#for i in range(len(t)):\n",
    "    #mfcc_display(np.transpose(t[i]))\n",
    "    #print(t[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# validation data: l2-normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mfcc1_val_n, mfcc2_val_n, same_val_n = loader_2.get_mfcc_pairs(default_validation_samples, period = \"validate\", preprocess = \"l2-normalize\")\n",
    "#for i in range(len(mfcc1_train_global)):\n",
    "#    mfcc_display(np.transpose(mfcc1_train_global[i]))\n",
    "#    mfcc_display(np.transpose(mfcc2_train_global[i]))\n",
    "#    print(\"label:\", same_train_global[i])\n",
    "\n",
    "#save to binary file\n",
    "path = \"binary_data/validation_normalize/\"\n",
    "file_mfcc1 = path+\"mfcc1_validation_normalize_\" + str(mfcc1_val_n.shape) + \"_\" + str(datetime.date.today()) + \".npy\"\n",
    "print(file_mfcc1)\n",
    "f = open(file_mfcc1, \"wb\")\n",
    "np.save(f, mfcc1_val_n)\n",
    "f.close()\n",
    "\n",
    "file_mfcc2 = path+\"mfcc2_validation_normalize_\" + str(mfcc2_val_n.shape) + \"_\" + str(datetime.date.today()) + \".npy\"\n",
    "print(file_mfcc2)\n",
    "f = open(file_mfcc2, \"wb\")\n",
    "np.save(f, mfcc2_val_n)\n",
    "f.close()\n",
    "\n",
    "file_label = path+\"label_validation_normalize_\" + str(same_val_n.shape) + \"_\" + str(datetime.date.today()) + \".npy\"\n",
    "print(file_label)\n",
    "f = open(file_label, \"wb\")\n",
    "np.save(f, same_val_n)\n",
    "f.close()\n",
    "\n",
    "#f = open(file_mfcc1, \"rb\")\n",
    "#t = np.load(f)\n",
    "#print(\"shape:\", t.shape)\n",
    "#for i in range(len(t)):\n",
    "    #mfcc_display(np.transpose(t[i]))\n",
    "    #print(t[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test data: global"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader_3 = WavMFCCLoader(speech_data_dir, wanted=default_test_words, mean = mfcc_mean, std = mfcc_std)\n",
    "mfcc1_test_g, mfcc2_test_g, same_test_g = loader_3.get_mfcc_pairs(default_test_samples, period = \"test\", preprocess = \"global\")\n",
    "\n",
    "#save to binary file\n",
    "path = \"binary_data/test_global/\"\n",
    "file_mfcc1 = path + \"mfcc1_test_global_\" + str(mfcc1_test_g.shape) + \"_\" + str(datetime.date.today()) + \".npy\"\n",
    "print(file_mfcc1)\n",
    "f = open(file_mfcc1, \"wb\")\n",
    "np.save(f, mfcc1_test_g)\n",
    "f.close()\n",
    "\n",
    "file_mfcc2 = path + \"mfcc2_test_global_\" + str(mfcc2_test_g.shape)+ \"_\" + str(datetime.date.today()) + \".npy\"\n",
    "print(file_mfcc2)\n",
    "f = open(file_mfcc2, \"wb\")\n",
    "np.save(f, mfcc2_test_g)\n",
    "f.close()\n",
    "\n",
    "file_label = path +\"same_test_global_\" + str(same_test_g.shape) + \"_\" + str(datetime.date.today()) + \".npy\"\n",
    "print(file_label)\n",
    "f = open(file_label, \"wb\")\n",
    "np.save(f, same_test_g)\n",
    "f.close()\n",
    "\n",
    "#f = open(file_label, \"rb\")\n",
    "#t = np.load(f)\n",
    "#print(\"shape:\", t.shape)\n",
    "#for i in range(len(t)):\n",
    "    #mfcc_display(np.transpose(t[i]))\n",
    "    #print(t[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test data: z-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mfcc1_test_z, mfcc2_test_z, same_test_z = loader_3.get_mfcc_pairs(default_test_samples, period = \"test\", preprocess = \"z-score\")\n",
    "\n",
    "#save to binary file\n",
    "path = \"binary_data/test_score/\"\n",
    "file_mfcc1 = path + \"mfcc1_test_score_\" + str(mfcc1_test_z.shape) + \"_\" + str(datetime.date.today()) + \".npy\"\n",
    "print(file_mfcc1)\n",
    "f = open(file_mfcc1, \"wb\")\n",
    "np.save(f, mfcc1_test_z)\n",
    "f.close()\n",
    "\n",
    "file_mfcc2 = path + \"mfcc2_test_score_\" + str(mfcc2_test_z.shape)+ \"_\" + str(datetime.date.today()) + \".npy\"\n",
    "print(file_mfcc2)\n",
    "f = open(file_mfcc2, \"wb\")\n",
    "np.save(f, mfcc2_test_z)\n",
    "f.close()\n",
    "\n",
    "file_label = path +\"same_test_score_\" + str(same_test_z.shape) + \"_\" + str(datetime.date.today()) + \".npy\"\n",
    "print(file_label)\n",
    "f = open(file_label, \"wb\")\n",
    "np.save(f, same_test_z)\n",
    "f.close()\n",
    "\n",
    "\n",
    "#f = open(file_mfcc2, \"rb\")\n",
    "#t = np.load(f)\n",
    "#print(\"shape:\", t.shape)\n",
    "#for i in range(len(t)):\n",
    "    #mfcc_display(np.transpose(t[i]))\n",
    "    #print(t[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test data: max-min-scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mfcc1_test_s, mfcc2_test_s, same_test_s = loader_3.get_mfcc_pairs(default_test_samples, period = \"test\", preprocess = \"max-min-scaler\")\n",
    "\n",
    "#save to binary file\n",
    "path = \"binary_data/test_scaler/\"\n",
    "file_mfcc1 = path + \"mfcc1_test_scaler_\" + str(mfcc1_test_s.shape) + \"_\" + str(datetime.date.today()) + \".npy\"\n",
    "print(file_mfcc1)\n",
    "f = open(file_mfcc1, \"wb\")\n",
    "np.save(f, mfcc1_test_s)\n",
    "f.close()\n",
    "\n",
    "file_mfcc2 = path + \"mfcc2_test_scaler_\" + str(mfcc2_test_s.shape)+ \"_\" + str(datetime.date.today()) + \".npy\"\n",
    "print(file_mfcc2)\n",
    "f = open(file_mfcc2, \"wb\")\n",
    "np.save(f, mfcc2_test_s)\n",
    "f.close()\n",
    "\n",
    "file_label = path +\"same_test_scaler_\" + str(same_test_s.shape) + \"_\" + str(datetime.date.today()) + \".npy\"\n",
    "print(file_label)\n",
    "f = open(file_label, \"wb\")\n",
    "np.save(f, same_test_s)\n",
    "f.close()\n",
    "\n",
    "#f = open(file_mfcc1, \"rb\")\n",
    "#t = np.load(f)\n",
    "#print(\"shape:\", t.shape)\n",
    "#for i in range(len(t)):\n",
    "    #mfcc_display(np.transpose(t[i]))\n",
    "    #print(t[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test data: l2-normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mfcc1_test_n, mfcc2_test_n, same_test_n = loader_3.get_mfcc_pairs(default_test_samples, period = \"test\", preprocess = \"l2-normalize\")\n",
    "\n",
    "#save to binary file\n",
    "path = \"binary_data/test_normalize/\"\n",
    "file_mfcc1 = path + \"mfcc1_test_normalize_\" + str(mfcc1_test_n.shape) + \"_\" + str(datetime.date.today()) + \".npy\"\n",
    "print(file_mfcc1)\n",
    "f = open(file_mfcc1, \"wb\")\n",
    "np.save(f, mfcc1_test_n)\n",
    "f.close()\n",
    "\n",
    "file_mfcc2 = path + \"mfcc2_test_normalize_\" + str(mfcc2_test_n.shape)+ \"_\" + str(datetime.date.today()) + \".npy\"\n",
    "print(file_mfcc2)\n",
    "f = open(file_mfcc2, \"wb\")\n",
    "np.save(f, mfcc2_test_n)\n",
    "f.close()\n",
    "\n",
    "file_label = path +\"same_test_normalize_\" + str(same_test_n.shape) + \"_\" + str(datetime.date.today()) + \".npy\"\n",
    "print(file_label)\n",
    "f = open(file_label, \"wb\")\n",
    "np.save(f, same_test_n)\n",
    "f.close()\n",
    "\n",
    "#f = open(file_mfcc1, \"rb\")\n",
    "#t = np.load(f)\n",
    "#print(\"shape:\", t.shape)\n",
    "#for i in range(len(t)):\n",
    "    #mfcc_display(np.transpose(t[i]))\n",
    "    #print(t[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
