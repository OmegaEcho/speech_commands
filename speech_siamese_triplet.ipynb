{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try triplet loss for speech command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import hashlib\n",
    "import math, time, datetime\n",
    "import os.path\n",
    "import random\n",
    "import re\n",
    "import sys\n",
    "import tarfile\n",
    "\n",
    "#print(sys.executable)\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import librosa as rosa\n",
    "import librosa.display\n",
    "from six.moves import urllib\n",
    "from six.moves import xrange  # pylint: disable=redefined-builtin\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Input, Dense, Conv2D, MaxPooling2D, Dropout, Flatten, Lambda, BatchNormalization, Activation, LSTM, GRU\n",
    "#from tensorflow.contrib.framework.python.ops import audio_ops as contrib_audio\n",
    "#from tensorflow.python.ops import io_ops\n",
    "#from tensorflow.python.platform import gfile\n",
    "#from tensorflow.python.util import compat\n",
    "\n",
    "default_number_of_mfcc=128\n",
    "default_sample_rate=16000\n",
    "default_hop_length=512 \n",
    "default_wav_duration=1 # 1 second\n",
    "default_train_samples=10000\n",
    "default_test_samples=100\n",
    "default_epochs=10\n",
    "default_batch_size=32\n",
    "default_wanted_words=[\"one\", \"two\", \"bed\", \"backward\", \"bird\", \"cat\", \"dog\", \"eight\", \"five\", \"follow\", \"forward\", \"four\", \"go\", \"happy\", \"house\", \"learn\", \"left\", \"marvin\", \"nine\", \"no\", \"off\", \"right\", \"seven\", \"sheila\", \"stop\", \"three\", \"tree\", \"visual\", \"wow\", \"zero\",\"up\"]\n",
    "#for mac\n",
    "#speech_data_dir=\"/Users/hermitwang/Downloads/speech_dataset\"\n",
    "#default_model_path=\"/Users/hermitwang/Downloads/pretrained/speech_siamese\"\n",
    "#for ubuntu\n",
    "#speech_data_dir=\"/home/hermitwang/TrainingData/datasets/speech_dataset\"\n",
    "#default_model_path=\"/home/hermitwang/TrainingData/pretrained/speech_siamese\"\n",
    "#for windows of work\n",
    "\n",
    "default_feature_dim = 4096\n",
    "\n",
    "speech_data_dir=\"/home/zhangjun/tensorflow/speech_siamese_zj/speech_dataset\"\n",
    "default_model_path=\"/home/zhangjun/tensorflow/speech_siamese_zj/trained\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_wav_mfcc(filename):\n",
    "    wav_loader, sample_rate = rosa.load(filename, sr=default_sample_rate)\n",
    "    #print(rosa.get_duration(wav_loader, sample_rate))\n",
    "    wav_mfcc = rosa.feature.mfcc(y=wav_loader, sr=default_sample_rate, n_mfcc=default_number_of_mfcc)\n",
    "    return wav_mfcc\n",
    "\n",
    "def get_default_mfcc_length(default_wav_duration=1):\n",
    "    length = int(math.ceil(default_wav_duration * default_sample_rate / default_hop_length))\n",
    "    return length\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "each words select: 2\n",
      "words number: 30\n",
      "total sample number: 60\n",
      "['one', 'one', 'two', 'two', 'bed', 'bed', 'backward', 'backward', 'bird', 'bird', 'cat', 'cat', 'dog', 'dog', 'eight', 'eight', 'five', 'five', 'follow', 'follow', 'forward', 'forward', 'four', 'four', 'go', 'go', 'happy', 'happy', 'house', 'house', 'learn', 'learn', 'left', 'left', 'marvin', 'marvin', 'nine', 'nine', 'no', 'no', 'off', 'off', 'right', 'right', 'seven', 'seven', 'sheila', 'sheila', 'stop', 'stop', 'three', 'three', 'tree', 'tree', 'visual', 'visual', 'wow', 'wow', 'zero', 'zero']\n",
      "(60, 128, 32)\n"
     ]
    }
   ],
   "source": [
    "class WavMFCCLoader(object):\n",
    "    def __init__(self, data_dir, wanted, validation_percentage=0, testing_percentage=0):\n",
    "        self.data_dir = data_dir\n",
    "        self.wanted = wanted\n",
    "        self.default_mfcc_length=get_default_mfcc_length(default_wav_duration)\n",
    "        self.wav_files = dict()\n",
    "        self.wav_file_index()\n",
    "        \n",
    "    def wav_file_index(self):\n",
    "        for dirpath, dirnames, files in os.walk(self.data_dir):\n",
    "            for name in files:\n",
    "                if name.lower().endswith('.wav'):\n",
    "                    word_name = dirpath.rsplit('/', 1)[1];\n",
    "                    if word_name in self.wanted:\n",
    "                        file_name = os.path.join(dirpath, name)\n",
    "                        #print(file_name, dirpath, word_name)\n",
    "    \n",
    "                        if word_name in self.wav_files.keys():\n",
    "                            self.wav_files[word_name].append(file_name)\n",
    "                        else:\n",
    "                            self.wav_files[word_name] = [file_name]\n",
    "                    \n",
    "        return self.wav_files\n",
    "\n",
    "\n",
    "    def wavs_to_mfcc_pair(self):\n",
    "        how_many_words = len(self.wanted)\n",
    "        a_index = random.randint(0, how_many_words - 1)\n",
    "        b_index = random.randint(0, how_many_words - 1)\n",
    "        a_wav_index = b_wav_index = -1\n",
    "        mfcc_pair = np.array([3, 1])\n",
    "        if (a_index > b_index):\n",
    "            a_wav_index = random.randint(0, len(self.wav_files[self.wanted[a_index]]) - 1)\n",
    "            b_wav_index = random.randint(0, len(self.wav_files[self.wanted[b_index]]) - 1)\n",
    "            mfcc_1 = load_wav_mfcc(self.wav_files[self.wanted[a_index]][a_wav_index])\n",
    "            mfcc_2 = load_wav_mfcc(self.wav_files[self.wanted[b_index]][b_wav_index])\n",
    "            mfcc_pair = 0            \n",
    "        else:\n",
    "            a_wav_index = random.randint(0, len(self.wav_files[self.wanted[a_index]]) - 1)\n",
    "            b_wav_index = random.randint(0, len(self.wav_files[self.wanted[a_index]]) - 1)\n",
    "            mfcc_1 = load_wav_mfcc(self.wav_files[self.wanted[a_index]][a_wav_index])\n",
    "            mfcc_2 = load_wav_mfcc(self.wav_files[self.wanted[a_index]][b_wav_index])\n",
    "            mfcc_pair = 1\n",
    "            \n",
    "        #print(\"aaa\", mfcc_1.shape, mfcc_2.shape)    \n",
    "        return mfcc_1, mfcc_2, mfcc_pair\n",
    "        \n",
    "    def get_mfcc_pairs(self, how_many):\n",
    "        mfcc1_data = np.zeros((how_many, default_number_of_mfcc, self.default_mfcc_length))\n",
    "        mfcc2_data = np.zeros((how_many, default_number_of_mfcc, self.default_mfcc_length))\n",
    "        same_data = np.zeros(how_many)\n",
    "        for i in range(0, how_many - 1):\n",
    "            \n",
    "            mfcc1_data_, mfcc2_data_, same_data[i] = self.wavs_to_mfcc_pair()\n",
    "            mfcc1_data[i, :, 0:mfcc1_data_.shape[1]] = mfcc1_data_\n",
    "            mfcc2_data[i, :, 0:mfcc2_data_.shape[1]] = mfcc2_data_\n",
    "            #np.append(mfcc1_data, mfcc1_)\n",
    "            #np.append(mfcc2_data, mfcc2_)\n",
    "            #np.append(same_data, same_)          \n",
    "        #print(mfcc_pairs)\n",
    "        return mfcc1_data, mfcc2_data, same_data\n",
    " \n",
    "    def get_mfccs(self, how_many):\n",
    "        mfccs = np.zeros((how_many, default_number_of_mfcc, self.default_mfcc_length))\n",
    "        mfcc_words = []\n",
    "        words_num = len(self.wanted)\n",
    "        for i in range(how_many):\n",
    "            word_index = random.randint(0, words_num - 1)\n",
    "            wav_index = random.randint(0, len(self.wav_files[self.wanted[word_index]]) - 1)\n",
    "            mfcc_ = load_wav_mfcc(self.wav_files[self.wanted[word_index]][wav_index])\n",
    "            mfccs[i, :, 0:mfcc_.shape[1]] = mfcc_\n",
    "            mfcc_words.append(self.wanted[word_index])\n",
    "        return mfccs, mfcc_words\n",
    "\n",
    "    def get_mfcc_triplet(self, how_many):\n",
    "        how_many_words = len(self.wanted)\n",
    "        #n = min([len(self.wav_files[self.wanted[d]]) for d in range(how_many_words)]) - 1\n",
    "        n = how_many\n",
    "        sample_number = how_many_words * n\n",
    "        print(\"each words select:\", n)\n",
    "        print(\"words number:\", how_many_words)\n",
    "        print(\"total sample number:\", sample_number)\n",
    "        anchor_data = np.zeros((sample_number, default_number_of_mfcc, self.default_mfcc_length))\n",
    "        positive_data = np.zeros((sample_number, default_number_of_mfcc, self.default_mfcc_length))\n",
    "        negative_data = np.zeros((sample_number, default_number_of_mfcc, self.default_mfcc_length))\n",
    "        \n",
    "        index = 0\n",
    "        anchor_words = []\n",
    "        for d in range(how_many_words):\n",
    "            for i in range(n):\n",
    "                np.random.shuffle(self.wav_files[self.wanted[d]])\n",
    "                anchor_index = self.wav_files[self.wanted[d]][i]\n",
    "                positive_index = self.wav_files[self.wanted[d]][i + 1]\n",
    "                inc = random.randrange(1, how_many_words)\n",
    "                dn = (d + inc) % how_many_words\n",
    "                negative_index = self.wav_files[self.wanted[dn]][i]\n",
    "                \n",
    "                anchor_ = load_wav_mfcc(anchor_index)\n",
    "                positive_ = load_wav_mfcc(positive_index)\n",
    "                negative_ = load_wav_mfcc(negative_index)\n",
    "                \n",
    "                anchor_data[index, :, 0:anchor_.shape[1]] = anchor_\n",
    "                positive_data[index, :, 0:positive_.shape[1]] = positive_\n",
    "                negative_data[index, :, 0:negative_.shape[1]] = negative_\n",
    "                \n",
    "                index = index + 1\n",
    "                anchor_words.append(self.wanted[d])\n",
    "        return anchor_data, positive_data, negative_data, anchor_words\n",
    "            \n",
    "loader = WavMFCCLoader(speech_data_dir, wanted=[\"one\", \"two\", \"bed\", \"backward\", \"bird\", \"cat\", \"dog\", \"eight\", \"five\", \"follow\", \"forward\", \"four\", \"go\", \"happy\", \"house\", \"learn\", \"left\", \"marvin\", \"nine\", \"no\", \"off\", \"right\", \"seven\", \"sheila\", \"stop\", \"three\", \"tree\", \"visual\", \"wow\", \"zero\"])\n",
    "a, p, n, w = loader.get_mfcc_triplet(2)\n",
    "print(w)\n",
    "print(a.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_keras_model(fingerprint_shape, is_training=True):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(input_shape=fingerprint_shape, filters=64, kernel_size=3, use_bias=False))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(MaxPooling2D())\n",
    "    #if (is_training):\n",
    "    #    model.add(Dropout(0.5))\n",
    "    model.add(Conv2D(filters=64, kernel_size=3, use_bias=False)) \n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(\"relu\"))\n",
    "\n",
    "    model.add(MaxPooling2D())\n",
    "    #if (is_training):\n",
    "    #    model.add(Dropout(0.5))\n",
    "    model.add(Conv2D(filters=64, kernel_size=3, use_bias=False))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(\"relu\"))\n",
    "\n",
    "    model.add(MaxPooling2D())\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(default_feature_dim))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(\"sigmoid\"))    \n",
    "    if (is_training):\n",
    "        model.add(Dropout(0.5))\n",
    "    #model.add(Dense(labels_count, activation=\"softmax\"))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_siamese_triplet_model(input_shape):\n",
    "    anchor_input = Input(input_shape)\n",
    "    positive_input = Input(input_shape)\n",
    "    negative_input = Input(input_shape)\n",
    "    \n",
    "    keras_model = create_keras_model(input_shape)\n",
    "    \n",
    "    anchor_encoder = keras_model(anchor_input)\n",
    "    positive_encoder = keras_model(positive_input)\n",
    "    negative_encoder = keras_model(negative_input)\n",
    "    \n",
    "    merged_vector = []\n",
    "    merged_vector.append(anchor_encoder)\n",
    "    merged_vector.append(positive_encoder)\n",
    "    merged_vector.append(negative_encoder)\n",
    "    \n",
    "    siamese_triplet_model = Model(inputs = [anchor_input, positive_input, negative_input], outputs = merged_vector)\n",
    "    return siamese_triplet_model, keras_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def triplet_loss_1(y_true, y_pred, alpha = 0.2):\n",
    "    anchor, positive, negative = y_pred[0], y_pred[1], y_pred[2]\n",
    "    pos_dist = tf.reduce_sum(tf.square(tf.subtract(anchor, positive)), -1)\n",
    "    neg_dist = tf.reduce_sum(tf.square(tf.subtract(anchor, negative)), -1)\n",
    "    basic_loss = tf.add(tf.subtract(pos_dist, neg_dist), alpha)\n",
    "    loss = tf.reduce_sum(tf.maximum(basic_loss, 0.0))\n",
    "    return loss\n",
    "\n",
    "def triplet_loss(y_true, y_pred, N = default_feature_dim, beta = default_feature_dim, epsilon = 1e-8):\n",
    "    anchor, positive, negative = y_pred[0], y_pred[1], y_pred[2]\n",
    "    pos_dist = tf.reduce_sum(tf.square(tf.subtract(anchor, positive)), -1)\n",
    "    neg_dist = tf.reduce_sum(tf.square(tf.subtract(anchor, negative)), -1)\n",
    "    \n",
    "    # -ln(-x/N + 1)\n",
    "    pos_dist = -tf.log(-tf.divide((pos_dist), beta) + 1 + epsilon)\n",
    "    neg_dist = -tf.log(-tf.divide((N - neg_dist), beta) + 1 + epsilon)\n",
    "    \n",
    "    loss = neg_dist + pos_dist\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_feature_dataset(anchor_words, x1_train, base_model):\n",
    "    feature_dic = dict()\n",
    "    index = 0\n",
    "    for word in anchor_words:\n",
    "        if not word in feature_dic.keys():\n",
    "            feature_ = base_model.predict(x1_train[index].reshape(1, default_number_of_mfcc, default_mfcc_length, 1))\n",
    "            feature_dic[word] = feature_[0, :]\n",
    "        index = index + 1\n",
    "    return feature_dic\n",
    "\n",
    "def siamese_triplet_train(train_sample=default_train_samples, wanted_words=default_wanted_words):\n",
    "    default_mfcc_length = get_default_mfcc_length(default_wav_duration)\n",
    "    siamese_triplet_model, base_model = create_siamese_triplet_model((default_number_of_mfcc, default_mfcc_length, 1))\n",
    "    siamese_triplet_model.compile(loss = triplet_loss, optimizer = 'adam')\n",
    "    \n",
    "    loader = WavMFCCLoader(speech_data_dir, wanted = wanted_words)\n",
    "    mfcc1_data, mfcc2_data, mfcc3_data, anchor_words = loader.get_mfcc_triplet(train_sample)\n",
    "    \n",
    "    x1_train = mfcc1_data.reshape((mfcc1_data.shape[0], default_number_of_mfcc, default_mfcc_length, 1))\n",
    "    x2_train = mfcc1_data.reshape((mfcc2_data.shape[0], default_number_of_mfcc, default_mfcc_length, 1))\n",
    "    x3_train = mfcc1_data.reshape((mfcc3_data.shape[0], default_number_of_mfcc, default_mfcc_length, 1))\n",
    "    \n",
    "    y_train_ = np.zeros((mfcc1_data.shape[0], default_feature_dim))\n",
    "    y_train = []\n",
    "    y_train.append(y_train_)\n",
    "    y_train.append(y_train_)\n",
    "    y_train.append(y_train_)\n",
    "    \n",
    "    siamese_triplet_model.fit(x = [x1_train, x2_train, x3_train], y = y_train, epochs = default_epochs, batch_size = default_batch_size)\n",
    "    \n",
    "    feature_dic = make_feature_dataset(anchor_words, x1_train, base_model)   \n",
    "    \n",
    "    base_model.save(default_model_path + \"\\speech_siamese_triplet_base\" + str(datetime.date.today()) + \".h5\")\n",
    "    \n",
    "    return feature_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "each words select: 2\n",
      "words number: 30\n",
      "total sample number: 60\n",
      "Epoch 1/10\n"
     ]
    }
   ],
   "source": [
    "print(\"train\")\n",
    "feature_dic = siamese_triplet_train(train_sample=2, wanted_words=[\"one\", \"two\", \"cat\", \"dog\", \"bed\", \"backward\", \"eight\", \"five\", \"follow\", \"forward\", \"four\", \"go\", \"happy\", \"house\", \"learn\", \"left\", \"marvin\", \"nine\", \"no\", \"off\", \"right\", \"seven\", \"sheila\", \"stop\", \"three\", \"tree\", \"visual\", \"wow\", \"zero\",\"up\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_distance(feature1, feature2):\n",
    "    dist = tf.reduce_sum(tf.square(tf.subtract(feature1, feature2)), -1)\n",
    "    result = tf.Session().run(dist)\n",
    "    return result\n",
    "\n",
    "def match_siamese_triplet_feature(feature_predict, word_label_predict, feature_dic):\n",
    "    print(\"prdict word:\", word_label_predict)\n",
    "    for word in feature_dic.keys():\n",
    "        distance = feature_distance(feature_predict, feature_dic[word])\n",
    "        print(\"dictionary word:\", word, \"distance:\", distance)\n",
    "    return\n",
    "\n",
    "def siamese_triplet_test(test_sample = default_test_samples, wanted_words = default_wanted_words, feature_dic = dict()):\n",
    "    default_mfcc_length = get_default_mfcc_length(default_wav_duration)\n",
    "    base_model = keras.models.load_model(default_model_path + \"\\speech_siamese_triplet_base\" + str(datetime.date.today()) + \".h5\")\n",
    "    \n",
    "    loader = WavMFCCLoader(speech_data_dir, wanted = wanted_words)\n",
    "    mfccs_test, words_test = loader.get_mfccs(test_samples)\n",
    "    \n",
    "    x_test = mfccs_test.reshape((test_samples, default_number_of_mfcc, default_mfcc_length, 1))\n",
    "    y_test = words_test\n",
    "    \n",
    "    features_predict = base_model.predict_on_batch(x_test)\n",
    "    for i in range(len(features_predict)):\n",
    "        match_result = match_siamese_triplet_feature(features_predict[i], y_test[i], feature_dic)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'feature_dic' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-985d51ebc7c0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"test\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msiamese_triplet_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwanted_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"five\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"follow\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_dic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeature_dic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'feature_dic' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"test\")\n",
    "siamese_triplet_test(test_samples = 1, wanted_words = [\"five\", \"follow\"], feature_dic = feature_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
